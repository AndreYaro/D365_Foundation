<?xml version="1.0" encoding="utf-8"?>
<AxClass xmlns:i="http://www.w3.org/2001/XMLSchema-instance">
	<Name>RetailConnSCDataBulkCopy</Name>
	<SourceCode>
		<Declaration><![CDATA[
using System.Collections.Specialized;
using Microsoft.Dynamics.Retail.CommerceDataExchange;

/// <summary>
/// The <c>RetailConnSCDataBulkCopy</c> class performs bulk copy of the data.
/// </summary>
class RetailConnSCDataBulkCopy
{
    tableName targetTableName;

    str tmpDataFilePath;

    container columnNames;
    container guidColumnNames;
    container physicalColumnNames;

    int rowsAffected;

    // See https://learn.microsoft.com/en-us/sql/relational-databases/replication/mssql-eng002627
    private const int DuplicateKeyViolationSqlErrorCode = 2627;

}
]]></Declaration>
		<Methods>
			<Method>
				<Name>bulkCopyToTargetTable</Name>
				<Source><![CDATA[
    /// <summary>
    /// performs a bulk copy of the source Csv data into the main AX target table.
    /// </summary>
    /// <exception cref="Exception::Error">
    /// Throws error if fail to copy the data to the target table.
    /// </exception>
    /// <exception cref="Exception::DuplicateKeyException">
    /// Throws duplicate key exception if bulk copy fails due to duplicate records.
    /// </exception>
    internal void bulkCopyToTargetTable()
    {
        StringCollection columnNameCollection = new StringCollection();
        StringCollection guidColumnNameCollection = new StringCollection();

        for (int i = 1; i <= conLen(columnNames); i++)
        {
            str columnName = conPeek(columnNames, i);
            columnNameCollection.Add(columnName);
        }

        for (int i = 1; i <= conLen(guidColumnNames); i++)
        {
            str columnName = conPeek(guidColumnNames, i);
            guidColumnNameCollection.Add(columnName);
        }

        System.Exception ex;
        System.Data.SqlClient.SqlException sqlException;
        boolean cleanUpSourceDataFile = true;
        try
        {
            Partition partitionId = getcurrentpartitionrecid();
            using (CsvDataReader reader = new CsvDataReader(tmpDataFilePath, columnNameCollection, guidColumnNameCollection, partitionId))
            {
                str connStr = this.getConnectionString();
                using (System.Data.SqlClient.SqlBulkCopy sqlBulkCopy = new System.Data.SqlClient.SqlBulkCopy(connStr))
                {
                    System.Data.SqlClient.SqlBulkCopyColumnMappingCollection colMapping = sqlBulkCopy.get_ColumnMappings();

                    for (int i = 1; i <= conLen(physicalColumnNames); ++i)
                    {
                        str col = conPeek(physicalColumnNames, i);
                        colMapping.Add(i-1, col);
                    }

                    sqlBulkCopy.set_DestinationTableName(this.targetTableName);
                    sqlBulkCopy.set_BulkCopyTimeout(RetailConnParameters::find().getSqlCommandTimeout());

                    sqlBulkCopy.WriteToServer(reader);
                }

                rowsAffected = reader.get_NumberOfRecordsRead();
            }
        }
        catch(sqlException)
        {
            if (sqlException.Number == RetailConnSCDataBulkCopy::DuplicateKeyViolationSqlErrorCode)
            {
                // do not cleanup the source Csv data file because DuplicateKeyException failure
                // could be retried using a deduplication logic.
                cleanUpSourceDataFile = false;
                throw Exception::DuplicateKeyException;
            }
            
            throw error(strFmt("Error when bulk inserting data. Target table: %1\n%2", this.targetTableName, sqlException.ToString()));
        }
        catch(ex)
        {
            throw error(strFmt("Error when bulk inserting data. Target table: %1\n%2", this.targetTableName, ex.ToString()));
        }
        finally
        {
            if (cleanUpSourceDataFile)
            {
                this.cleanTempDataFile();
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>bulkCopyToTemp</Name>
				<Source><![CDATA[
    /// <summary>
    /// Method performs the bulk copy of the physical name of the table to the temporarly created table.
    /// </summary>
    /// <param name="physicalTempDBTableName">
    /// Name of the physical temp table.
    /// </param>
    /// <exception cref="Exception::Error">
    /// Throws error if fail to copy the data to the temporary table.
    /// </exception>
    public void bulkCopyToTemp(str physicalTempDBTableName)
    {
        StringCollection columnNameCollection = new StringCollection();
        StringCollection guidColumnNameCollection = new StringCollection();

        for (int i = 1; i <= conLen(columnNames); i++)
        {
            str columnName = conPeek(columnNames, i);
            columnNameCollection.Add(columnName);
        }

        for (int i = 1; i <= conLen(guidColumnNames); i++)
        {
            str columnName = conPeek(guidColumnNames, i);
            guidColumnNameCollection.Add(columnName);
        }

        System.Data.SqlClient.SqlBulkCopy sqlBulkCopy;
        Microsoft.Dynamics.Retail.CommerceDataExchange.CsvDataReader reader;

        try
        {
            Partition partitionId = getcurrentpartitionrecid();
            reader = new Microsoft.Dynamics.Retail.CommerceDataExchange.CsvDataReader(tmpDataFilePath, columnNameCollection, guidColumnNameCollection, partitionId);

            str connStr = this.getConnectionString();
            sqlBulkCopy = new System.Data.SqlClient.SqlBulkCopy(connStr);

            System.Data.SqlClient.SqlBulkCopyColumnMappingCollection colMapping = sqlBulkCopy.get_ColumnMappings();

            for (int i = 1; i <= conLen(physicalColumnNames); ++i)
            {
                str col = conPeek(physicalColumnNames, i);
                colMapping.Add(i-1, col);
            }

            sqlBulkCopy.set_DestinationTableName(physicalTempDBTableName);
            sqlBulkCopy.set_BulkCopyTimeout(RetailConnParameters::find().getSqlCommandTimeout());

            sqlBulkCopy.WriteToServer(reader);

            rowsAffected = reader.get_NumberOfRecordsRead();

            sqlBulkCopy.Dispose();
            reader.Dispose();
            this.cleanTempDataFile();
        }
        catch(Exception::CLRError)
        {
            System.Exception clrException = CLRInterop::getLastException();
            str exceptionMessage = clrException.ToString();
            exceptionMessage = strFmt("Error when bulk inserting data. Target table: %1\n%2",
                targetTableName,
                exceptionMessage);

            if (sqlBulkCopy)
            {
                sqlBulkCopy.Dispose();
            }

            if (reader)
            {
                reader.Dispose();
            }

            this.cleanTempDataFile();

            throw error(exceptionMessage);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>cleanTempDataFile</Name>
				<Source><![CDATA[
    /// <summary>
    /// Cleans up temp data file.
    /// </summary>
    /// <remarks>
    /// fileStream.Close(), closes the current stream and releases any resources (such as sockets and file handles) associated
    /// with the current stream.
    /// fileStream.Dispose(), releases all resources used by the Stream.
    /// </remarks>
    public void cleanTempDataFile()
    {
        // clean up temp data file
        // Never throw. Error here is almost always caused by a previously caught error.

        System.Exception clrException;
        str exceptionMessage;

        try
        {
            if (tmpDataFilePath && System.IO.File::Exists(tmpDataFilePath))
            {
                System.IO.File::Delete(tmpDataFilePath);
            }
        }
        catch(Exception::CLRError)
        {
            clrException = CLRInterop::getLastException();
            exceptionMessage = clrException.ToString();
            error(exceptionMessage);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>getConnectionString</Name>
				<Source><![CDATA[
    private str getConnectionString()
    {
        System.Data.SqlClient.SqlConnectionStringBuilder        dbConnectionStringBuilder;
        dbConnectionStringBuilder = new System.Data.SqlClient.SqlConnectionStringBuilder();

        Microsoft.Dynamics.ApplicationPlatform.Environment.IApplicationEnvironment env =
                Microsoft.Dynamics.ApplicationPlatform.Environment.EnvironmentFactory::GetApplicationEnvironment();

        Microsoft.Dynamics.ApplicationPlatform.Environment.Settings.IDataAccessConfig dataAccess = env.DataAccess;

        str serverName = dataAccess.DbServer;
        str databaseName = dataAccess.Database;
        str sqlUser = dataAccess.SqlUser;
        str sqlPwd = dataAccess.SqlPwd;

        dbConnectionStringBuilder.DataSource = serverName;
        dbConnectionStringBuilder.InitialCatalog = databaseName;
        dbConnectionStringBuilder.UserID = sqlUser;
        dbConnectionStringBuilder.Password = sqlPwd;
        dbConnectionStringBuilder.IntegratedSecurity = false;
        dbConnectionStringBuilder.Encrypt = true;
        dbConnectionStringBuilder.TrustServerCertificate = true;

        return dbConnectionStringBuilder.ToString();
    }

]]></Source>
			</Method>
			<Method>
				<Name>getRowsAffected</Name>
				<Source><![CDATA[
    /// <summary>
    /// Method returns the count of records read from the <c>xmlDataReader</c>.
    /// </summary>
    /// <returns>
    /// Count of records read.
    /// </returns>
    public int getRowsAffected()
    {
        return rowsAffected;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetTargetTableName</Name>
				<Source><![CDATA[
    /// <summary>
    /// Method returns the target table name.
    /// </summary>
    /// <returns>
    /// The target table name.
    /// </returns>
    public tableName GetTargetTableName()
    {
        return targetTableName;
    }

]]></Source>
			</Method>
			<Method>
				<Name>insertIntoTargetTable</Name>
				<Source><![CDATA[
    /// <summary>
    /// Insert data from staging temporary table into target table.
    /// </summary>
    /// <param name = "_tempTableCursor">The TempDB table cursor.</param>
    public void insertIntoTargetTable(Common _tempTableCursor)
    {
        container companies = this.getCompanies(_tempTableCursor);

        this.deleteDuplicateRecords(_tempTableCursor, companies);

        // insert to target table
        boolean isGlobal = RetailConnReplicationUtilities::isGlobalTable(this.targetTableName);

        TableId tid = _tempTableCursor.TableId;
        FieldId dataAreaIdFieldId;

        if (!isGlobal)
        {
            dataAreaIdFieldId = fieldName2Id(tid, 'DataAreaId');
        }

        Query q = new Query();
        QueryBuildDataSource ds = q.addDataSource(tid);
        ds.fields().dynamic(NoYes::No);
        q.clearAllFields();

        QueryBuildFieldList fl = ds.fields();
        Map fm = new Map(Types::String, Types::Container);

        for (int i = 1; i <= conLen(this.columnNames); ++i)
        {
            FieldName fieldName = conPeek(this.columnNames, i);

            FieldId fid = fieldName2Id(tid, fieldName);

            if (fid <= 0)
            {
                // invalid field, warning and skip
                Global::warning(strFmt("%1.%2 does not exist and is skipped for data uploading.", tableId2Name(tid), fieldName));
                continue;
            }

            // skip DataAreaId
            if (!isGlobal && fid == dataAreaIdFieldId)
            {
                continue;
            }

            fl.addField(fid);
            fm.insert(fieldName, [ds.uniqueId(), fieldName]);
        }

        DictTable dictTarget = new DictTable(tid);
        boolean isCallingTableEventsDisabled = RetailCdxFeatureControl::isTableEventsDuringUploadJobDisabled();

        ttsbegin;

        if (isGlobal)
        {
            Common target = dictTarget.makeRecord();
            QueryRun qr = new QueryRun(q);
            Common t = dictTarget.makeRecord();
            t.setTempDB();
            t.linkPhysicalTableInstance(_tempTableCursor);
            qr.setRecord(t);

            // To skip calling table methods
            target.skipDataMethods(isCallingTableEventsDisabled);
            Query::insert_recordset(target, fm, qr.query());
        }
        else
        {
            for (int i = 1; i <= conLen(companies); ++i)
            {
                DataAreaId le = conPeek(companies, i);

                changecompany(le)
                {
                    Common target = dictTarget.makeRecord();

                    QueryRun qr = new QueryRun(q);
                    Common t = dictTarget.makeRecord();
                    t.setTempDB();
                    t.linkPhysicalTableInstance(_tempTableCursor);
                    qr.setRecord(t);

                    // To skip calling table methods
                    target.skipDataMethods(isCallingTableEventsDisabled);
                    target.skipEvents(isCallingTableEventsDisabled);
                    Query::insert_recordset(target, fm, qr.query());
                }
            }
        }

        ttscommit;
    }

]]></Source>
			</Method>
			<Method>
				<Name>new</Name>
				<Source><![CDATA[
    /// <summary>
    /// Initializes a new instance of the <c> RetailConnSCDataBulkCopy</c> class.
    /// Initializes the ID of the table and columns.
    /// </summary>
    /// <param name="_targetTableName">
    /// Name of the target table.
    /// </param>
    /// <param name="_columnNames">
    /// Container with the field names.
    /// </param>
    /// <param name="_tmpDataFilePath">
    /// Server side data file path if data file is directly copied over
    /// </param>
    public void new(TableName _targetTableName, container _columnNames, str _tmpDataFilePath)
    {
        this.rowsAffected = 0;

        TableId tid = tableName2id(_targetTableName);

        // table should exist
        if (tid == 0)
        {
            throw Global::error(strFmt("@SYS75683", _targetTableName));
        }

        targetTableName = _targetTableName;

        for (int i = 1; i <= conLen(_columnNames); i++)
        {
            str columnName = conPeek(_columnNames, i);
            fieldId fid = fieldName2id(tid, columnName);

            if (fid == 0)
            {
                throw Global::error(strFmt("@SYS75684", columnName, _targetTableName));
            }

            columnNames += columnName;

            DictField dictField = new DictField(tid, fid);
            str physicalColumnName = dictField.name(DbBackend::Sql);
            physicalColumnNames += physicalColumnName;

            if (dictField.baseType() == Types::Guid)
            {
                guidColumnNames += columnName;
            }
        }

        // PARTITON
        fieldId  fid = fieldName2id(tid, 'PARTITION');
        DictField dictField = new DictField(tid, fid);
        str physicalColumnName = dictField.name(DbBackend::Sql);
        physicalColumnNames += physicalColumnName;
        tmpDataFilePath = _tmpDataFilePath;
    }

]]></Source>
			</Method>
			<Method>
				<Name>deleteDuplicateRecords</Name>
				<Source><![CDATA[
    /// <summary>
    /// Delete duplicate records in temp table before inserting.
    /// </summary>
    /// <param name = "_tempTableCursor">The temp table cursor.</param>
    private void deleteDuplicateRecords(Common _tempTableCursor, container _companies)
    {
        TableId tid = tableName2id(this.targetTableName);
        DictTable dictTargetTable = new DictTable(tid);
        QueryBuildDataSource ds, ds2;
        int numberOfFields;
        FieldId fid;
        Common t, cursor2;
        boolean dataAreaIDLinked = false;
        FieldId dataAreaIdFieldId;
        DataAreaID le;
        boolean isGlobal = (conLen(_companies) <= 0);

        if (!isGlobal)
        {
            dataAreaIdFieldId = fieldName2Id(tid, 'DataAreaId');
        }

        DictIndex di = new DictIndex(tid, dictTargetTable.primaryIndex());
        numberOfFields = di.numberOfFields();

        Query q = new Query();
        ds = q.addDataSource(tid);
        ds.fields().dynamic(NoYes::No);
        ds2 = ds.addDataSource(tid);
        ds2.joinMode(JoinMode::ExistsJoin);
        ds2.fields().dynamic(NoYes::No);

        for (int i = 1; i <= di.numberOfFields(); ++i)
        {
            fid = di.field(i);
            ds2.addLink(fid, fid);

            if (!isGlobal && fid == dataAreaIdFieldId)
            {
                dataAreaIDLinked = true;
            }
        }

        if (!isGlobal && !dataAreaIDLinked)
        {
            ds2.addLink(dataAreaIdFieldId, dataAreaIdFieldId);
        }

        q.clearAllFields();
        ds.fields().addField(fieldName2Id(tid, 'RecId'));

        if (isGlobal)
        {
            QueryRun qr = new QueryRun(q);

            t = dictTargetTable.makeRecord();
            t.setTempDB();
            t.linkPhysicalTableInstance(_tempTableCursor);
            t.selectForUpdate(true);

            qr.setRecord(t);

            ttsbegin;

            while (qr.next())
            {
                cursor2 = qr.getNo(1);
                // use doDelete to skip the delete overridden logics as the upload sync only uses the temp table version of the target table for staging
                // and does not need to trigger the extra overridden logics.
                cursor2.doDelete();
            }

            ttscommit;
        }
        else
        {
            for (int i = 1; i <= conLen(_companies); ++i)
            {
                le = conPeek(_companies, i);

                changecompany(le)
                {
                    QueryRun qr = new QueryRun(q);

                    t = dictTargetTable.makeRecord();
                    t.setTempDB();
                    t.linkPhysicalTableInstance(_tempTableCursor);
                    t.selectForUpdate(true);

                    qr.setRecord(t);

                    ttsbegin;

                    while (qr.next())
                    {
                        cursor2 = qr.getNo(1);
                        // use doDelete to skip the delete overridden logics as the upload sync only uses the temp table version of the target table for staging
                        // and doesnt need to trigger the extra overridden logics.
                        cursor2.doDelete();
                    }

                    ttscommit;
                }
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>getCompanies</Name>
				<Source><![CDATA[
    private container getCompanies(Common _tempTableCursor)
    {
        TableId tid = tableName2id(this.targetTableName);
        DictTable dictTargetTable = new DictTable(tid);
        Common t;
        container companies = conNull();

        t = dictTargetTable.makeRecord();
        t.setTempDB();
        t.linkPhysicalTableInstance(_tempTableCursor);

        boolean isGlobal = RetailConnReplicationUtilities::isGlobalTable(this.targetTableName);

        if (!isGlobal)
        {
            while select crossCompany DataAreaId from t group by DataAreaId
            {
                if (!RetailConnReplicationUtilities::companyExists(t.DataAreaId))
                {
                    throw Global::error(strFmt("@SYS10666", t.DataAreaId));
                }

                companies += t.dataAreaId;
            }
        }

        return companies;
    }

]]></Source>
			</Method>
		</Methods>
	</SourceCode>
</AxClass>