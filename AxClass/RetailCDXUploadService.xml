<?xml version="1.0" encoding="utf-8"?>
<AxClass xmlns:i="http://www.w3.org/2001/XMLSchema-instance">
	<Name>RetailCDXUploadService</Name>
	<SourceCode>
		<Declaration><![CDATA[
using Microsoft.Dynamics.Retail.CommerceDataExchange;
using Microsoft.Dynamics.Application.Instrumentation;

/// <summary>
///    The <c>RetailCDXUploadService</c> class is a support class for the <c>CDXRealTimeService</c> class.
/// </summary>
/// <remarks>
///    This class is used for CDX upload service APIs.
/// </remarks>
// This is a framework class. Customizing this class may cause problems Real-Time Service in channels.
public class RetailCDXUploadService
{
}
]]></Declaration>
		<Methods>
			<Method>
				<Name>GetDataUploadParameters</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the data upload parameters object containing information required for generating upload packages from the target datastore.
    /// </summary>
    /// <param name = "dataStoreName">Data store name</param>
    /// <returns>The <c>RetailCDXDataUploadParameters</c> object.</returns>
    internal static RetailCDXDataUploadParameters GetDataUploadParameters(str dataStoreName)
    {
        RetailConnDatabaseProfile dataStore = RetailConnDatabaseProfile::find(dataStoreName);

        RetailCDXDataUploadParameters dataUploadParameters = new RetailCDXDataUploadParameters();
        RetailCDXDataStore cdxDataStore = new RetailCDXDataStore(dataStore.Name, dataStore.RecId);
        dataUploadParameters.DataStore(cdxDataStore);

        if (dataStore)
        {
            RetailCDXDataStoreHeartbeatLog::LogAccess(dataStore.RecId);

            int uploadInterval                      = RetailCDXUploadService::GetUploadInterval(dataStoreName);
            List uploadJobPackageRequestList        = RetailCDXUploadService::GetUploadJobPackageRequestList(dataStore);

            // next upload session Id is only required when processing upload package fromm online channel database
            if (dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase)
            {
                int64 nextLocalUploadSessionId = RetailCDXUploadService::GetNextLocalUploadSessionId(dataStore.RecId);
                dataUploadParameters.NextLocalUploadSessionId(nextLocalUploadSessionId);
            }

            dataUploadParameters.UploadInterval(uploadInterval);
            dataUploadParameters.UploadJobPackageRequestList(uploadJobPackageRequestList);
        }

        List cdxFeatureControlList = RetailCdxFeatureControl::getFeatureControlList();
        dataUploadParameters.FeatureControlList(cdxFeatureControlList);

        return dataUploadParameters;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetUploadJobPackageRequestList</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the list of upload job package requests.
    /// </summary>
    /// <param name = "_dataStore">The data store.</param>
    /// <returns>List of upload job package requests.</returns>
    private static List GetUploadJobPackageRequestList(RetailConnDatabaseProfile _dataStore)
    {
        List uploadJobPackageRequestList = new List(Types::Class);

        // if data sync to and from the specified datastore is paused then return empty upload pkg request list.
        if (_dataStore.isDataStoreSynchronizationPaused() && !_dataStore.AllowUploadDuringSyncPause)
        {
            return uploadJobPackageRequestList;
        }

        RetailConnDatabaseProfile dataStore;
        RetailConnScheduleJobMapping retailConnScheduleJobMapping;
        RetailConnSchedulerJobTable retailConnSchedulerJobTable;
        RetailCDXScheduleDataGroup retailCDXScheduleDataGroup;
        RetailConnSchedule retailConnSchedule;

        while select jobId from retailConnSchedulerJobTable
            join retailConnScheduleJobMapping
                where retailConnScheduleJobMapping.SchedulerJobId == retailConnSchedulerJobTable.jobId &&
                        retailConnScheduleJobMapping.enabled == NoYes::Yes &&
                        retailConnSchedulerJobTable.IsUpload == NoYes::Yes
            join retailCDXScheduleDataGroup
                where retailCDXScheduleDataGroup.Schedule == retailConnScheduleJobMapping.ScheduleRecId
            join RecId, DataStoreType from dataStore
                where dataStore.DataGroup == retailCDXScheduleDataGroup.DataGroup &&
                        dataStore.Name == _dataStore.Name
            exists join retailConnSchedule
                where retailConnSchedule.RecId == retailConnScheduleJobMapping.ScheduleRecId &&
                        retailConnSchedule.Active == NoYes::Yes
        {
            str uploadUrl;
            str targetStorage;
            RetailCDXUploadSession rerunUploadSession;

            str jobId            = retailConnSchedulerJobTable.jobId;
            str uploadDefinition = RetailCDXUploadService::GetUploadJobDefinition(_dataStore.Name, jobId);

            // RerunUploadSessionId and uploadLinkParameter are not used/required for OfflineDatabase upload data sync scenario.
            // Rerunning upload session is only done against the ("online") channel database.
            // offline upload sync (i.e. offlinedb to online channeldb) doesnt upload pkg to azure blob hence does not require UploadLoad Link parameters
            if (dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase)
            {
                rerunUploadSession = RetailCDXUploadSession::getOldestRerunUploadSession(_dataStore.Name, jobId);

                RetailAsyncClientUploadParameter uploadLinkParameter = RetailCDXUploadService::GetUploadUri(_dataStore.Name);
                if (uploadLinkParameter != null)
                {
                    uploadUrl            = uploadLinkParameter.paramUploadUrl();
                    targetStorage        = uploadLinkParameter.paramTargetStorage();
                }
                else
                {
                    // caller or client will handle invalid upload url gracefully
                    ApplicationEventSource::EventWriteCDXUploadUriRetrievalFailureWarning(dataStore.Name, jobId);
                }
            }

            RetailCDXUploadJobPackageRequest uploadJobRequest = new RetailCDXUploadJobPackageRequest();
            uploadJobRequest.JobId(jobId);
            uploadJobRequest.UploadJobDefintion(uploadDefinition);
            uploadJobRequest.UploadUrl(uploadUrl);
            uploadJobRequest.TargetStorage(targetStorage);

            if (rerunUploadSession)
            {
                uploadJobRequest.RerunUploadSessionId(rerunUploadSession.LocalUploadSessionId);
                uploadJobRequest.UploadSessionRerunType(rerunUploadSession.UploadSessionRerunType);
            }

            uploadJobPackageRequestList.addEnd(uploadJobRequest);
        }

        return uploadJobPackageRequestList;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetUploadJobDefinitions</Name>
				<Source><![CDATA[
    /// <summary>
    /// Get list of upload jobs with definition for on premise channel upload or MPOS offline upload.
    /// </summary>
    /// <param name = "dataStoreName">Data store name</param>
    /// <returns>Upload job definition list</returns>
    public static List GetUploadJobDefinitions(str dataStoreName)
    {
        return RetailCDXUploadService::GetDataStoreUploadJobDefinitions(dataStoreName);
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetUploadJobDefinition</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the upload job definition. 
    /// </summary>
    /// <param name = "dataStoreName">Data store name.</param>
    /// <param name = "jobId">The job Id.</param>
    /// <returns>The upload job definition list.</returns>
    public static str GetUploadJobDefinition(str dataStoreName, RetailConnJobId jobId)
    {
        str uploadJobDefinition;

        container uploadJobDefinitions = list2Con(RetailCDXUploadService::GetDataStoreUploadJobDefinitions(dataStoreName, jobId));

        if (conLen(uploadJobDefinitions) == 1)
        {
            uploadJobDefinition = conPeek(uploadJobDefinitions, 1);
        }

        return uploadJobDefinition;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetDataStoreUploadJobDefinitions</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the list of upload job definitions for the specified datastore.
    /// </summary>
    /// <param name = "dataStoreName">Data store name.</param>
    /// <param name = "_jobIdFilter">The job Id used to filter the upload job definition list. If not specified all applicable definitions are returned</param>
    /// <returns>The list of upload job definitions.</returns>
    private static List GetDataStoreUploadJobDefinitions(str dataStoreName, RetailConnJobId _jobIdFilter = '')
    {
        RetailCDXDataGroup dataGroup;
        RetailConnSchedulerJobTable job;
        RetailConnSchedule schedule;
        RetailConnScheduleJobMapping scheduleJob;
        RetailCDXScheduleDataGroup scheduleDataGroup;
        RetailConnSchedulerSubjobTable subjob;
        RetailConnSchedulerJobLine jobLine;

        RetailConnDatabaseProfile dataStore = RetailConnDatabaseProfile::find(dataStoreName);

        if (!dataStore)
        {
            throw Global::error(strfmt("@Retail:CDXDataStoreNotExistError", dataStoreName));
        }

        if (!dataStore.DataGroup)
        {
            throw Global::error(strfmt("@Retail:CdxDataGroupNotSetError", dataStoreName));
        }

        List uploadJobs = new List(Types::String);

        // if data sync is paused for the datastore then return empty upload job definition list 
        // so that the client doesn't generate an upload session.
        if (dataStore.isDataStoreSynchronizationPaused())
        {
            ApplicationEventSource::EventWriteCDXDataStoreDataSyncPausedByUser(dataStoreName, newGuid());
            return uploadJobs;
        }

        // given that application updates may not be bundled with binary updates
        // we need to verify whether the necessary functionality is available on the current binary references
        System.Type readRequestType = new ReadRequest('.', '.').GetType();
        System.Reflection.MethodInfo readRequestAddExtensionTableMethod = readRequestType.GetMethod("AddExtensionTable");
        boolean extensionTableSupportAvailable = readRequestAddExtensionTableMethod != null;

        const str replicationCounterFieldNameConst = 'ReplicationCounterFieldName';

        while select JobId, description
          from job
          order by job.jobId
            where job.IsUpload == NoYes::Yes
                  && (job.jobId == _jobIdFilter || _jobIdFilter == '')
          exists join scheduleJob
            where scheduleJob.SchedulerJobId == job.JobId
          exists join schedule
            where schedule.RecId == scheduleJob.ScheduleRecId
          exists join scheduleDataGroup
            where scheduleDataGroup.Schedule == schedule.RecId
          exists join dataGroup
            where scheduleDataGroup.DataGroup == dataGroup.RecId
               && dataGroup.RecId == dataStore.DataGroup
               && job.RetailConnChannelSchema == dataGroup.ChannelSchema
        {
            ReadRequestHeader header;
            header = new ReadRequestHeader();
            header.JobID = job.jobId;
            header.JobDescription = job.translatedDescription();
            header.SourceDataStoreName = dataStoreName;

            while select *
            from subjob
                exists join jobline
                    where subjob.subJobId == jobLine.subJobId
                       && jobLine.enabled == NoYes::Yes
                       && jobLine.JobId == job.JobId
            {
                ReadRequest readRequest;

                if (!subjob.replicationCounterFieldName)
                {
                    throw Global::error(strfmt("@Retail:RetailCDXMissingReplicationCounterFieldName", subjob.subJobId));
                }

                if (dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase)
                {
                    readRequest = new ReadRequest(subjob.ChannelTableName, subjob.AXTableName);
                }
                else if (dataStore.DataStoreType == RetailCDXDataStoreType::OfflineDatabase)
                {
                    readRequest = new ReadRequest(subjob.ChannelTableName, subjob.ChannelTableName);
                }
                else
                {
                    throw Global::error(strfmt("@Retail:CdxDataStoreTypeIsInvalid", dataStoreName));
                }

                // use reflection to set ReplicationCounterFieldName property
                ReflectionHelper::trySetObjectProperty(readRequest, replicationCounterFieldNameConst, subjob.replicationCounterFieldName);

                RetailConnSchedulerSubjobFieldList fieldMapping;

                while select fromFieldName, toFieldName, conversionType, conversionValue
                from fieldMapping
                    where fieldMapping.subjobId == subjob.subJobId
                {
                    // Skip ReplicationCounter field mapping as it is not required for offline to online upload sync. Since its an Identity column including it in the mapping will cause offline upload sync issue.
                    if (dataStore.DataStoreType == RetailCDXDataStoreType::OfflineDatabase && fieldMapping.toFieldName == subjob.replicationCounterFieldName)
                    {
                        continue;
                    }

                    // Ignore DataAreaId as it will be added after the loop.
                    if (fieldMapping.toFieldName == 'DataAreaId')
                    {
                        continue;
                    }

                    FieldName fromField = fieldMapping.fromFieldName;
                    FieldName toField = fieldMapping.toFieldName;
                    str convValue = fieldMapping.conversionValue;
                    RetailConnConversionType convType = fieldMapping.conversionType;

                    TableId tid = tableName2Id(subjob.AXTableName);
                    DictField targetField = new DictField(tid, fieldName2Id(tid, toField));

                    if (!targetField || !targetField.name(DbBackend::Sql))
                    {
                        // if configuration key is not enabled for a field, skip
                        continue;
                    }

                    if (convType == RetailConnConversionType::None)
                    {
                        readRequest.AddTransferColumnPair(fromField, toField);
                    }
                    else if (convType == RetailConnConversionType::Constant)
                    {
                        readRequest.AddTransferColumnPair(fromField, toField, convValue);
                    }
                }
                // while loop transfer field list

                if (!RetailConnReplicationUtilities::isGlobalTable(subjob.AXTableName))
                {
                    readRequest.AddTransferColumnPair('DATAAREAID', 'DataAreaId');
                }

                // add extension tables, if any
                if (extensionTableSupportAvailable)
                {
                    RetailConnLocationDesignTable extensionDesignTable;
                    RetailConnLocationDesignTable parentDesignTable;

                    while select locationTableName from extensionDesignTable
                    exists join parentDesignTable
                    where parentDesignTable.locationTableName == subJob.ChannelTableName &&
                          parentDesignTable.RetailConnChannelSchema == subJob.RetailConnChannelSchema &&
                          extensionDesignTable.ParentTable == parentDesignTable.RecId
                    {
                        System.Object[] argumentArray = new System.Object[1]();
                        argumentArray.SetValue(extensionDesignTable.locationTableName, 0);
                        readRequestAddExtensionTableMethod.Invoke(readRequest, argumentArray);
                    }
                }

                // add to filters: >, <= on replication counter field with value "-1"
                readRequest.AddFilter(
                    subjob.replicationCounterFieldName,
                    FilterOperator::GreaterThan,
                    '-1');

                readRequest.AddFilter(
                    subjob.replicationCounterFieldName,
                FilterOperator::LessThanOrEqualTo,
                    '-1');

                header.AddReadRequest(readRequest);
            }
            // while loop - subjob

            uploadJobs.addEnd(header.ToXml());
        }
        // while loop - job

        return uploadJobs;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetRerunUploadSessionId</Name>
				<Source><![CDATA[
    /// <summary>
    /// Get channel rerun upload session id specific to a jobId and channel.
    /// </summary>
    /// <param name = "dataStoreName">Data store name</param>
    /// <param name = "jobId">Job id</param>
    /// <returns>Rerun upload session id</returns>
    public static int64 GetRerunUploadSessionId(str dataStoreName, str jobId)
    {
        RetailCDXUploadSession uploadSession = RetailCDXUploadSession::getOldestRerunUploadSession(dataStoreName, jobId);

        int64 rerunUploadSessionId;

        if (uploadSession)
        {
            rerunUploadSessionId = uploadSession.LocalUploadSessionId;
        }

        return rerunUploadSessionId;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetUploadInterval</Name>
				<Source><![CDATA[
    /// <summary>
    /// Get upload session interval for a data store.
    /// </summary>
    /// <param name = "dataStoreName">Data store name.</param>
    /// <returns>Upload session interval</returns>
    public static int GetUploadInterval(str dataStoreName)
    {
        RetailConnDatabaseProfile dbProfile;
        RetailCDXSchedulerInterval schedulerInterval;

        select firstonly schedulerInterval join dbProfile
            where dbProfile.SchedulerInterval == schedulerInterval.RecId
            && dbProfile.Name == dataStoreName;

        return schedulerInterval.UploadInterval;
    }

]]></Source>
			</Method>
			<Method>
				<Name>CreateUploadSession</Name>
				<Source><![CDATA[
    /// <summary>
    /// Create upload session.
    /// </summary>
    /// <param name = "uploadSession">The upload session data contract.</param>
    /// <returns>Created upload session Id.</returns>
    public static RetailCDXSessionNumber CreateUploadSession(RetailAsyncClientUploadSession uploadSession)
    {
        RetailConnDatabaseProfile dataStore;

        select firstonly RecId
            from dataStore
            where dataStore.Name == uploadSession.paramDataStoreName();

        if (!dataStore)
        {
            throw Global::error(strfmt("@Retail:CDXDataStoreNotExistError", uploadSession.paramDataStoreName()));
        }

        return RetailCDXUploadHelper::CreateUploadSession_v2(datastore.RecId, uploadSession.paramJobID(),
                uploadSession.paramScheduleRecID(), uploadSession.paramSuccess(), uploadSession.paramTargetStorage(),
                uploadSession.paramFileSize(), uploadSession.paramCheckSum(), uploadSession.paramLocalUploadSessionId(),
                uploadSession.paramErrorMessage(), uploadSession.paramRerunFor(), uploadSession.paramUploadSessionRerunType());
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetUploadUri</Name>
				<Source><![CDATA[
    /// <summary>
    /// Get upload url with valid SAS token and blob GUID ID for client to upload file.
    /// </summary>
    /// <param name = "dataStoreName">Data store name.</param>
    public static RetailAsyncClientUploadParameter GetUploadUri(str dataStoreName)
    {
        RetailConnDatabaseProfile dataStore;
        RetailConnParameters schedulerParameter;
        RetailAsyncClientUploadParameter uploadParameter = null;
        str stagingFileName;

        schedulerParameter = RetailConnParameters::find();

        select firstonly DataGroup, RecId
            from dataStore
            where dataStore.Name == dataStoreName;

        if (!dataStore)
        {
            throw Global::error(strfmt("@Retail:CDXDataStoreNotExistError", dataStoreName));
        }

        if (!dataStore.DataGroup)
        {
            throw Global::error(strfmt("@Retail:CdxDataGroupNotSetError", dataStoreName));
        }

        stagingFileName = RetailCDXUploadHelper::GenerateUploadDataFileName(dataStore.RecId);

        try
        {
            uploadParameter = RetailCDXPackageStore::getUploadParameter(
            dataStore.DataGroup,
            RetailCDXDownloadUpload::Upload,
            stagingFileName,
            schedulerParameter.getSasTokenTimeout()
            );
        }
        catch (Exception::CLRError)
        {
            // do nothing
        }

        return uploadParameter;
    }

]]></Source>
			</Method>
			<Method>
				<Name>UpdateUploadSessionStatus</Name>
				<Source><![CDATA[
    /// <summary>
    /// Update upload session status in database.
    /// </summary>
    /// <param name = "dataStoreName">Data store name</param>
    /// <param name = "uploadSessionId">Upload session id</param>
    /// <param name = "status">Upload session status</param>
    /// <param name = "message">Session message</param>
    public static void UpdateUploadSessionStatus(str dataStoreName, int64 uploadSessionId, RetailCDXUploadSessionStatus status, str message)
    {
        RetailCDXUploadSession uploadSession;
        RetailConnDatabaseProfile dbProfile;
        boolean fileIsValid;

        ttsbegin;

        select firstonly dbProfile where dbProfile.Name == dataStoreName;
        if (!dbProfile)
        {
            throw Global::error(strfmt("@Retail:CDXDataStoreNotExistError", dataStoreName));
        }

        select firstonly forupdate uploadSession
            where uploadSession.DataStore == dbProfile.RecId
            && uploadSession.UploadSessionId == uploadSessionId;

        if (!uploadSession)
        {
            throw Global::error("@Retail:CDXUploadSessionNotFoundError");
        }

        // Before an upload session can be updated, it must already exist.
        uploadSession.Status = status;
        uploadSession.Message = message;

        if (status == RetailCDXUploadSessionStatus::Uploaded)
        {
            fileIsValid = Microsoft.Dynamics.Retail.SynchLibrary.Utility.FileCheck::ValidateFile(uploadSession.UploadPath, uploadSession.Checksum);

            if (!fileIsValid)
            {
                str errMsg = "@Retail:CDXInvalidFileError";
                uploadSession.Status = RetailCDXUploadSessionStatus::UploadFailed;
                uploadSession.Message = errMsg;
                status = RetailCDXUploadSessionStatus::UploadFailed;
            }
            else
            {
                uploadSession.DateUploaded = DateTimeUtil::utcNow();
            }
        }

        uploadSession.update();

        RetailCDXUploadService::CreateUploadSessionLog(dbProfile.RecId, uploadSessionId, status, message);

        ttsCommit;
    }

]]></Source>
			</Method>
			<Method>
				<Name>CancelRerunnedUploadSession</Name>
				<Source><![CDATA[
    /// <summary>
    /// Updates reruned upload session status to Canceled with error message.
    /// </summary>
    /// <param name = "dataStoreName">Data store name</param>
    /// <param name = "uploadSessionId">The channel local upload session id</param>
    public static void CancelRerunnedUploadSession(str dataStoreName, int64 uploadSessionId)
    {
        RetailCDXUploadSession uploadSession;
        RetailConnDatabaseProfile dbProfile;

        ttsbegin;

        select firstonly dbProfile where dbProfile.Name == dataStoreName;
        if (!dbProfile)
        {
            throw Global::error(strfmt("@Retail:CDXDataStoreNotExistError", dataStoreName));
        }

        select firstonly forupdate uploadSession
            where uploadSession.DataStore == dbProfile.RecId
            && uploadSession.LocalUploadSessionId == uploadSessionId;

        if (!uploadSession)
        {
            throw Global::error("@Retail:CDXUploadSessionNotFoundError");
        }

        // Updates rerun upload session status to Canceled and mark Rerun field to Executed.
        uploadSession.Status = RetailCDXUploadSessionStatus::Canceled;
        uploadSession.Rerun = RetailCDXUploadSessionRerun::Executed;
        uploadSession.Message = strfmt("@Retail:RetailCdxRerunUploadSessionMissingErrorMessage", uploadSession.UploadSessionId, dataStoreName);
        uploadSession.update();

        ttsCommit;
    }

]]></Source>
			</Method>
			<Method>
				<Name>GetNextLocalUploadSessionId</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the next local upload session identifier for the specified datastore name.
    /// </summary>
    /// <param name = "datastoreName">The datastore name.</param>
    /// <returns>The next local upload session identifier.</returns>
    internal static int64 GetNextLocalUploadSessionId(RecId datastoreRecId)
    {
        RetailCDXUploadSession retailCDXUploadSession;

        select maxof(LocalUploadSessionId)
                from retailCDXUploadSession
                where retailCDXUploadSession.DataStore == dataStoreRecId;

        return retailCDXUploadSession.LocalUploadSessionId + 1;
    }

]]></Source>
			</Method>
			<Method>
				<Name>CreateUploadSessionLog</Name>
				<Source><![CDATA[
    /// <summary>
    /// Create upload session log.
    /// </summary>
    /// <param name = "dbProfileRecId">Data store rec id.</param>
    /// <param name = "uploadSessionId">Uplaod session id.</param>
    /// <param name = "status">Status</param>
    /// <param name = "message">Message</param>
    private static void CreateUploadSessionLog(int64 dbProfileRecId, int64 uploadSessionId, RetailCDXUploadSessionStatus status, str message)
    {
        RetailCDXUploadSessionLog uploadSessionLog;
        uploadSessionLog.initValue();
        uploadSessionLog.DataStore = dbProfileRecId;
        uploadSessionLog.UploadSessionId = uploadSessionId;
        uploadSessionLog.DateCreated = DateTimeUtil::utcNow();
        uploadSessionLog.Message = message;
        uploadSessionLog.Status = status;
        uploadSessionLog.insert();
    }

]]></Source>
			</Method>
			<Method>
				<Name>UpdateUploadSessionRerun</Name>
				<Source><![CDATA[
    /// <summary>
    /// Update rerun status for upload sessions.
    /// </summary>
    /// <param name = "dbProfileRecId">Data store rec id.</param>
    /// <param name = "rerunFor">Session id for which rerun is executed.</param>
    /// <param name = "rerunStatus">Rerun status</param>
    private static void UpdateUploadSessionRerun(int64 dbProfileRecId, int64 rerunFor, RetailCDXUploadSessionRerun rerunStatus)
    {
        RetailCDXUploadSession uploadSession;
        RetailConnDatabaseProfile dbProfile;
        boolean rerunUploadSessionFound = false;

        while select forupdate uploadSession
            where uploadSession.DataStore == dbProfileRecId
            && uploadSession.UploadSessionId == rerunFor
        {
            uploadSession.Rerun = rerunStatus;
            rerunUploadSessionFound = true;
        }

        if (!rerunUploadSessionFound)
        {
            str msg = strfmt("@Retail:CDXFailedToGetUploadSessionError", rerunFor);
            throw Global::error(msg);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>updateMetadataSyncVersion</Name>
				<Source><![CDATA[
    private static void updateMetadataSyncVersion(RetailCDXMetadataSyncVersion _newCounter)
    {
        RetailCDXHQMessageDBProfile hqMessageDBProfile;

        ttsBegin;
        hqMessageDBProfile = RetailCDXHQMessageDBProfile::find(true);
        hqMessageDBProfile.LastMetadataSyncVersion = _newCounter;
        hqMessageDBProfile.update();
        ttsCommit;
    }

]]></Source>
			</Method>
		</Methods>
	</SourceCode>
</AxClass>