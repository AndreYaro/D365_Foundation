<?xml version="1.0" encoding="utf-8"?>
<AxClass xmlns:i="http://www.w3.org/2001/XMLSchema-instance">
	<Name>RetailCdxCsvDataOutput</Name>
	<SourceCode>
		<Declaration><![CDATA[
using Microsoft.Dynamics.Application.Instrumentation;

/// <summary>
/// The <c>RetailCdxCsvDataOutput</c> class outputs AX data into data package containing CSV files.
/// </summary>
class RetailCdxCsvDataOutput extends RetailCDXDataOutput
{
    private RetailCDXCSVDataWriterWrapper writerProxy;
    private QueryBuildFieldList headerFieldList;

    Microsoft.Dynamics.Retail.CommerceDataExchange.CsvDataWriter writer; // not used anymore.
    Microsoft.Dynamics.Retail.CommerceDataExchange.CsvDataWriter writer_delete;
    str dataFileName;  // not used anymore.
    str targetChannelTableName;
    BinData binaryData;
    FieldId subjobRecFieldId;
    boolean filterDuplicateSubjobRecords;
    
    List fieldTypeList;
    List sourceFieldIDList;
    List targetFieldNameList;
    List constFieldValueList;
    Query q;

    RetailCdxSessionLogger logger;

}
]]></Declaration>
		<Methods>
			<Method>
				<Name>parmWriterProxy</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal RetailCDXCSVDataWriterWrapper parmWriterProxy()
    {
        return this.writerProxy;
    }

]]></Source>
			</Method>
			<Method>
				<Name>beginSession</Name>
				<Source><![CDATA[
    /// <summary>
    /// Begins the session.
    /// </summary>
    public void beginSession()
    {
        super();

        ctContext.beginSessions(workDir);

        binaryData = new BinData();

        logger = new RetailCdxSessionLogger();
        logger.setSessions(ctContext.getSessionNumbers());
    }

]]></Source>
			</Method>
			<Method>
				<Name>beginTable</Name>
				<Source><![CDATA[
    /// <summary>
    /// Begins table.
    /// </summary>
    /// <param name="channelTableName">
    /// Channel table name.
    /// </param>
    protected void beginTable(str channelTableName)
    {
        this.targetChannelTableName = channelTableName;

        Set sessionTypesToBeWrittenTo = ctContext.getSessions().keySet();

        // during incremental sync, if the subjob, in the context of the current execution, is marked to skip data sync from the datafiltered version of the session
        // then remove the DataFiltered session type from the list of session types for which the csv writer would generate a csv packet.
        // Note: for full sync since we have to generate empty csv packet for skipped subjobs (so as to force the client to clean records 
        //        already in the target datastore) we will need to initialize the writer with both session types.
        if (!ctContext.paramIsInitSync() && this.paramSubjobContext().paramAllowSkipDataSync())
        {
            sessionTypesToBeWrittenTo.remove(RetailCDXDownloadSessionType::DataFiltered);
        }

        this.prepareWriterProxy(sessionTypesToBeWrittenTo);
    }

]]></Source>
			</Method>
			<Method>
				<Name>prepareWriterProxy</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal void prepareWriterProxy(Set _sessionTypesToBeWrittenTo)
    {
        writerProxy = new RetailCDXCSVDataWriterWrapper(_sessionTypesToBeWrittenTo, this.targetChannelTableName, workDir);
    }

]]></Source>
			</Method>
			<Method>
				<Name>cleanUp</Name>
				<Source><![CDATA[
    /// <summary>
    /// Cleans up the session.
    /// </summary>
    public void cleanUp()
    {
        if (writerProxy)
        {
            writerProxy.Dispose();
            writerProxy = null;
        }

        if (writer_delete)
        {
            writer_delete.Dispose();
            writer_delete = null;
        }

        super();
    }

]]></Source>
			</Method>
			<Method>
				<Name>endSession</Name>
				<Source><![CDATA[
    /// <summary>
    /// Ends the session.
    /// </summary>
    public void endSession()
    {
        ctContext.endSessions(workDir, logger);

        super();
    }

]]></Source>
			</Method>
			<Method>
				<Name>endTable</Name>
				<Source><![CDATA[
    /// <summary>
    /// Ends table.
    /// </summary>
    protected void endTable()
    {
        Set extensionTableNames = this.getExtensionTables(this.retailConnSubJobId);

        Map dataFileContextMap = writerProxy.GetDownloadSessionContextMap();

        this.paramSubjobContext().paramDataFileContextMap(dataFileContextMap);

        ctContext.addDataFileToSessions(dataFileContextMap, this.paramSubjobContext().paramAXSourceTableName(), this.targetChannelTableName, extensionTableNames);

        writerProxy.Dispose();
        writerProxy = null;
    }

]]></Source>
			</Method>
			<Method>
				<Name>getExtensionTables</Name>
				<Source><![CDATA[
    private Set getExtensionTables(RetailConnSubJobId _subJobId)
    {
        RetailConnLocationDesignTable parentDesignTable;
        RetailConnLocationDesignTable extensionDesignTable;
        Set extensionTableNames = new Set(Types::String);

        RetailConnSchedulerSubjobTable subJob = RetailConnSchedulerSubjobTable::find(_subJobId);
            
        while select locationTableName from extensionDesignTable
            exists join parentDesignTable
            where parentDesignTable.locationTableName == subJob.ChannelTableName &&
                parentDesignTable.RetailConnChannelSchema == subJob.RetailConnChannelSchema &&
                extensionDesignTable.ParentTable == parentDesignTable.RecId
        {
            extensionTableNames.add(extensionDesignTable.locationTableName);
        }

        return extensionTableNames;
    }

]]></Source>
			</Method>
			<Method>
				<Name>writeFieldName</Name>
				<Source><![CDATA[
    /// <summary>
    /// Writes the field name.
    /// </summary>
    /// <param name = "_tableName">The current table.</param>
    /// <param name = "_fieldName">The name of the field.</param>
    /// <param name = "_fieldType">The type of the field.</param>
    /// <returns>The number of fields written.</returns>
    [Hookable(false)]
    protected int writeFieldName(
        TableName                _tableName,
        str                      _fieldName,
        RetailCDXChannelDataType _fieldType)
    {
        writerProxy.WriteFieldName(_fieldName);

        return 1;
    }

]]></Source>
			</Method>
			<Method>
				<Name>writeUTCDateTimeValue</Name>
				<Source><![CDATA[
    /// <summary>
    /// Writes a utc datetime field.
    /// </summary>
    /// <param name = "_cursor">The current record that is being written.</param>
    /// <param name = "_fieldId">The id of the field that is being written.</param>
    /// <param name = "_fieldName">The name of the field that is being written.</param>
    [Hookable(false)]
    protected void writeUTCDateTimeValue(
        Common                                                          _cursor,
        FieldId                                                         _fieldId,
        str                                                             _fieldName)
    {
        writerProxy.WriteDateTimeValue(DateTimeUtil::anyToDateTime(_cursor.(_fieldId)));
    }

]]></Source>
			</Method>
			<Method>
				<Name>writeFieldNames</Name>
				<Source><![CDATA[
    /// <summary>
    /// Writes the field names.
    /// </summary>
    /// <param name = "_tableName">The current record that is being written.</param>
    /// <param name = "_itorTargetFieldName">The id of the field that is being written.</param>
    /// <param name = "_itorFieldType">The name of the field that is being written.</param>
    /// <returns>The number of columns written.</returns>
    [Hookable(false)]
    protected int writeFieldNames(
        TableName       _tableName,
        ListEnumerator _itorTargetFieldName,
        ListEnumerator _itorFieldType)
    {
        int totalColumnCount;
        while (_itorTargetFieldName.moveNext())
        {
            _itorFieldType.moveNext();

            totalColumnCount += this.writeFieldName(_tableName, strUpr(_itorTargetFieldName.current()), _itorFieldType.current());
        }

        return totalColumnCount;
    }

]]></Source>
			</Method>
			<Method>
				<Name>postWriteRecord</Name>
				<Source><![CDATA[
    /// <summary>
    /// called after a record is written.
    /// </summary>
    /// <param name = "_bufferWritten">The current record that is being written.</param>
    [Hookable(false)]
    internal void postWriteRecord(Common _bufferWritten)
    {
        // This method is empty on purpose in order to enable extensibility.
    }

]]></Source>
			</Method>
			<Method>
				<Name>isDuplicateRecord</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal boolean isDuplicateRecord(RecId _lastRecId, RecId _currentRecId)
    {
        return _lastRecId >= _currentRecId;
    }

]]></Source>
			</Method>
			<Method>
				<Name>output</Name>
				<Source><![CDATA[
    private void output(RetailConnSubJobId subjobID)
    {
        QueryRun qr;
        Common cursor;
        RetailConnSchedulerSubjobTable subjob;
        FieldId fid;

        RetailCDXChannelDataType fieldType;
        str targetFieldName;
        RecId lastRecId;

        ListEnumerator itorSourceFieldID, itorTargetFieldName, itorFieldType, itorConstValue;

        itorSourceFieldID = sourceFieldIDList.getEnumerator();
        itorTargetFieldName = targetFieldNameList.getEnumerator();
        itorFieldType = fieldTypeList.getEnumerator();
        itorConstValue = constFieldValueList.getEnumerator();

        select firstOnly AXTableName, ChannelTableName
            from subjob
            where subjob.subJobId == subjobID;

        qr = new QueryRun(q);

        if (!RetailConnReplicationUtilities::isTableTempDB(subjob.axTableName))
        {
            // if source is not a tempDB type table and need to use FilteredRecordsTempTable (i.e. <c>RetailCDXChangeRefTable2</c> temp table) then set the FilteredRecordsTempTable buffer.
            // and if useFilteredRecordsTempTable flag is true, it means that it already joined with changeTrackingResultTable (if it's delta sync)
            if (this.shouldUseFilteredRecordsTempTables())
            {
                if (ctContext.paramIsCacheBasedQueryEnabled())
                {
                    if (ctContext.paramIsInitSync())
                    {
                        RetailTmpCDXDataDistributionFilteredRecords fullSyncFilteredRecordsTempTable = ctContext.getFullSyncFilteredRecordsTempTableInstance(tableName2Id(subjob.axTableName));

                        // if entity level record filtering is enabled for the subjob then group the rows selected for syncing by RefRecId to remove any duplicates AND get minof(skipRecord).
                        if (this.paramSubjobContext().parmShouldFilterCdxEntityData())
                        {
                            // **Meaning of minof(skipRecord):
                            //      * If minof(skipRecord) == 1  it means that specific recordId came from table nodes in the tbl distribution that are all tagged as an entity marked to be skipped during package
                            //          generation of the 'DataFiltered' (lite weight) version of  the download session.
                            //      * If minof(skipRecord) == 0 the minof(skipRecord) is 0 it means that the specific recordId is atleast from one table node in the tbl distribution that is NOT tagged as an entity marked to be skipped.

                            RetailTmpCDXDataDistributionFilteredRecords distinctFullSyncFilteredRecordsTempTable;

                            insert_recordset distinctFullSyncFilteredRecordsTempTable (RefRecID, SkipRecord)
                                select RefRecID, minof(SkipRecord) from fullSyncFilteredRecordsTempTable
                                group by fullSyncFilteredRecordsTempTable.RefRecID;

                            qr.setRecord(distinctFullSyncFilteredRecordsTempTable);
                        }
                        else
                        {
                            qr.setRecord(fullSyncFilteredRecordsTempTable);
                        }
                    }
                    else
                    {
                        RetailTmpCDXDataDistributionDeltaSyncFilteredRecords deltaSyncFilteredRecordsTempTable = ctContext.getDeltaSyncFilteredRecordsTempTableInstance(tableName2Id(subjob.axTableName));

                        // if entity level record filtering is enabled for the subjob then group the rows selected for syncing by RefRecId to remove any duplicates AND get minof(skipRecord). 
                        if (this.paramSubjobContext().parmShouldFilterCdxEntityData())
                        {
                            RetailTmpCDXDataDistributionDeltaSyncFilteredRecords distinctDeltaSyncFilteredRecordsTempTable;

                            insert_recordset distinctDeltaSyncFilteredRecordsTempTable (RefRecID, SkipRecord)
                                select RefRecID, minof(SkipRecord) from deltaSyncFilteredRecordsTempTable      // refer to comment above for the **Meaning of minof(skipRecord)
                                group by deltaSyncFilteredRecordsTempTable.RefRecID
                                where deltaSyncFilteredRecordsTempTable.ChildNodeID <= 0;

                            qr.setRecord(distinctDeltaSyncFilteredRecordsTempTable);
                        }
                        else
                        {
                            qr.setRecord(deltaSyncFilteredRecordsTempTable);
                        }
                    }
                }
                else
                {
                    // if entity level record filtering is enabled for the subjob then group the rows selected for syncing by RefTableId and RefRecId to remove any duplicates AND get minof(skipRecord).
                    if (this.paramSubjobContext().parmShouldFilterCdxEntityData())
                    {
                        RetailCDXChangeRefTable2 distinctFilterRecords;

                        insert_recordset distinctFilterRecords (RefTableID, RefRecID, SkipRecord)
                            select RefTableID, RefRecID, minof(SkipRecord) from ref   // refer to comment above for the **Meaning of minof(skipRecord)
                            group by ref.RefRecID, ref.RefTableID
                            where ref.RefTableID == tableName2Id(this.paramSubjobContext().paramAXSourceTableName());

                        qr.setRecord(distinctFilterRecords);
                    }
                    else
                    {
                        qr.setRecord(ref);
                    }
                }
            }
            else
            {
                if (!ctContext.paramIsInitSync())
                {
                    // if it is delta sync and no need to use FilteredRecordsTempTable, set change tracking result table buffer
                    RetailCDXChangeRefTable1 changeTrackingResultTable = ctContext.openChangeRefTable1();

                    qr.setRecord(changeTrackingResultTable);
                }

                // if the table is not global then set the targetLegalEntityTempTable buffer
                if (!RetailConnReplicationUtilities::isGlobalTable(subjob.AXTableName))
                {
                    RetailTmpCDXTargetLegalEntity targetLegalEntityTempTable = ctContext.openTargetLegalEntityTempTable();
                    qr.setRecord(targetLegalEntityTempTable);
                }
            }
        }
        else
        {
            RetailInventDimLegacy inventDimLegacyTemp = ctContext.openTempDBTable(tableStr(RetailInventDimLegacy)); // get the temp table initialized in the datasync context i.e. ctContext.
            qr.setRecord(inventDimLegacyTemp); //if tempDB type subjob table then set the buffer of the tempDB datasource with the buffer initialized in ctContext.
        }

        this.beginTable(subjob.ChannelTableName);

        this.retailConnSubJobId = subjobID;

        int columnCount = this.writeFieldNames(subjob.AXTableName, itorTargetFieldName, itorFieldType);

        if(columnCount == 0)
        {
            str errorMsg = strFmt("@Retail:RetailSchedulerSubjobEmptyColumnError", subjobID);
            throw Global::error(errorMsg);
        }

        this.paramSubJobContext().paramColumnCount(columnCount);

        boolean skipSubJobSyncForDataFilteredSession = this.paramSubJobContext().paramAllowSkipDataSync();

        boolean shouldFilterCdxEntityData = this.paramSubJobContext().parmShouldFilterCdxEntityData();
        FieldId skipRecordFieldId = this.paramSubJobContext().getSkipRecordFieldId();

        while (qr.next())
        {
            itorSourceFieldID.reset();
            itorTargetFieldName.reset();
            itorFieldType.reset();
            itorConstValue.reset();

            // the first datasource of the query is the source table from which we are reading the rows to be synced. check dsMain the setUp method.
            cursor = qr.getNo(1);

            if (filterDuplicateSubjobRecords)
            {
                // The last RecId that was written must be strictly smaller than the current one since we order by RecId while writing
                // If the last RecId is greater than or equal to the current one, we know its a duplicate entry.
                int64 currentRecId = any2int64(cursor.(subjobRecFieldId));
                if (this.isDuplicateRecord(lastRecId, currentRecId))
                {
                    ApplicationEventSource::EventWriteRetailCdxCsvDataOutputDuplicateEntryInSubjob(funcName(), strFmt('Duplicate entry for recid %1. Last inserted recid %2.', currentRecId, lastRecId));
                    continue;
                }

                lastRecId = currentRecId;
            }

            // Note that qr.getNo(2) will retrieve the datasource of the temp tables that contain the skipRecord value of the currently selected row.
            //    This is done in prepareFilteredRecordsCacheTempTableDS method where, if shouldFilterCdxEntityData is enabled then the datasource of the temp table (that contains the list of records to sync)
            //    is added to the source tables datasource (dsMain in the setup method) and inner joined. Hence getNo(2) always gives the temptable DS added to the the source datasource (dsMain)
            //    and we can get the skiprecord value of the current row from this datasource.

            // read the skipRecord value for the selected row to determine if it should be excluded from the 'DataFiltered' (data lite) version of the download session package.
            boolean excludeRowFromDataFilteredSessionType = skipSubJobSyncForDataFilteredSession ||                                                          // if subjob skipped automatically skip all records
                                                            (shouldFilterCdxEntityData ? any2Enum(qr.getNo(2).(skipRecordFieldId)) == NoYes::Yes : false);   // if job/subjob are not marked to be skipped use the skipRecord value for the selected row to determine if it should be excluded

            writerProxy.parmExcludeRowFromDataFilteredSessionType(excludeRowFromDataFilteredSessionType);

            writerProxy.NewRecord();

            while (itorSourceFieldID.moveNext())
            {
                itorTargetFieldName.moveNext();
                itorFieldType.moveNext();
                itorConstValue.moveNext();

                targetFieldName = itorTargetFieldName.current();
                fieldType = itorFieldType.current();

                if (fieldType == RetailCDXChannelDataType::ConstValue)
                {
                    writerProxy.WriteStringValue(itorConstValue.current());
                }
                else
                {
                    fid = itorSourceFieldID.current();

                    switch (fieldType)
                    {
                        case RetailCDXChannelDataType::Int:
                            writerProxy.WriteIntValue(any2int(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::Enum:
                            writerProxy.WriteIntValue(enum2int(any2enum(cursor.(fid))));
                            break;

                        case RetailCDXChannelDataType::Long:
                            writerProxy.WriteInt64Value(any2int64(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::String:
                            writerProxy.WriteStringValue(any2str(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::Decimal:
                            writerProxy.WriteDecimalValue(any2real(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::Date:
                            writerProxy.WriteDateTimeValue(any2date(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::DateTime:
                            this.writeUTCDateTimeValue(cursor, fid, targetFieldName);
                            break;

                        case RetailCDXChannelDataType::Guid:
                            writerProxy.WriteGuidValue(any2guid(cursor.(fid)));
                            break;

                        case RetailCDXChannelDataType::Binary:
                            if (cursor.(fid))
                            {
                                writerProxy.WriteStringValue(this.encodeBinaryField(cursor, fid));
                            }
                            else
                            {
                                writerProxy.WriteStringValue('');
                            }
                            break;
                    }
                }
            }

            this.postWriteRecord(cursor);
        }

        this.endTable();
    }

]]></Source>
			</Method>
			<Method>
				<Name>encodeBinaryField</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal str encodeBinaryField(Common _cursor, FieldId _fieldId)
    {
        this.parmBinData().setData(_cursor.(_fieldId));
        return this.parmBinData().base64Encode();
    }

]]></Source>
			</Method>
			<Method>
				<Name>parmBinData</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal BinData parmBinData()
    {
        return this.binaryData;
    }

]]></Source>
			</Method>
			<Method>
				<Name>parmQueryBuildFieldList</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal QueryBuildFieldList parmQueryBuildFieldList()
    {
        return this.headerFieldList;
    }

]]></Source>
			</Method>
			<Method>
				<Name>postWriteDeleteFieldNames</Name>
				<Source><![CDATA[
    /// <summary>
    /// called after field names is written.
    /// </summary>
    [Hookable(false)]
    internal void postWriteDeleteFieldNames()
    {
        // This method is empty on purpose in order to enable extensibility.
    }

]]></Source>
			</Method>
			<Method>
				<Name>postWriteDeleteRecord</Name>
				<Source><![CDATA[
    /// <summary>
    /// called after a record is written.
    /// </summary>
    /// <param name = "_bufferWritten">The current record that is being written.</param>
    [Hookable(false)]
    internal void postWriteDeleteRecord(Common _bufferWritten)
    {
        // This method is empty on purpose in order to enable extensibility.
    }

]]></Source>
			</Method>
			<Method>
				<Name>processDeleteSubjob</Name>
				<Source><![CDATA[
    /// <summary>
    /// Processes deletion of subjob.
    /// </summary>
    protected void processDeleteSubjob()
    {
        int deletedRowsAffected = 0;
        RetailCDXFileSize deleteDataFileSize = 0;

        logger.logDataOutputStartProcessingDelete(deleteAXTableName);

        boolean isSourceTableTemp = RetailConnReplicationUtilities::isTableTempDB(deleteAXTableName);

        str suffix = subStr(guid2str(newGuid()), 2, 36);
        str dataFileName_delete = strFmt('DELETE_%1_%2.csv', deleteTargetTableName, suffix);
        str dataFilePath_delete = System.IO.Path::Combine(workDir, dataFileName_delete);
        writer_delete = new Microsoft.Dynamics.Retail.CommerceDataExchange.CsvDataWriter(dataFilePath_delete);

        for (int i = 1; i <= conLen(deletePKTarget); ++i)
        {
            str fieldName = conPeek(deletePKTarget, i);
            writer_delete.WriteFieldName(fieldName);
        }

        this.postWriteDeleteFieldNames();

        Query deleteQ = new Query();
        QueryBuildDataSource deleteDS = deleteQ.addDataSource(tableNum(RetailCDXChangeRefTable3));
        deleteQ.clearAllFields();

        deleteQ.skipAutoOrderBy(true);

        QueryBuildFieldList deleteDSFieldList = deleteDS.fields();
        deleteDSFieldList.dynamic(NoYes::No);
        deleteDSFieldList.clearFieldList();

        QueryBuildRange range = deleteDS.addRange(fieldNum(RetailCDXChangeRefTable3, RefTableID));
        range.value(queryValue(deleteSourceTableID));

        boolean orderByPrimaryIndex = this.paramSubjobContext().paramDataSyncContext().paramIsSortCdxPackageByPrimaryIndexEnabled();

        for(int i = 1; i <= conLen(this.deletePKTarget); i++)
        {
            FieldId fid = conPeek(deleteRefTableFieldID, i);
            deleteDSFieldList.addField(fid);

            if (orderByPrimaryIndex)
            {
                deleteDS.addSortField(fid, SortOrder::Ascending);
            }
        }

        QueryRun deleteQr = new QueryRun(deleteQ);
        deleteQr.setRecord(deleteRef);

        while (deleteQr.next())
        {
            Common cursor = deleteQr.getNo(1);

            writer_delete.NewRecord();

            for (int i = 1; i <= conLen(deletePKTarget); ++i)
            {
                str targetFieldName = conPeek(deletePKTarget, i);
                FieldId fid = conPeek(deleteRefTableFieldID, i);
                str pkValue = cursor.(fid);

                if (!pkvalue && targetFieldName == 'DATAAREAID' && (singleTargetLE || isSourceTableTemp))
                {
                    writer_delete.WriteStringValue(singleTargetLE);
                }
                else
                {
                    writer_delete.WriteStringValue(pkValue);
                }
            }

            this.postWriteDeleteRecord(cursor);

            deletedRowsAffected++;
        }

        this.paramSubjobContext().paramPackedDeletedRows(deletedRowsAffected);

        writer_delete.Dispose();
        writer_delete = null;

        if (deletedRowsAffected > 0)
        {
            Set extensionTableNames = this.getExtensionTables(this.retailConnSubJobId);
            ctContext.addDeleteDataFileToSessions(this.deleteAXTableName, this.deleteTargetTableName, dataFileName_delete, extensionTableNames, deletedRowsAffected);

            System.IO.FileInfo sessionFileInfo = new System.IO.FileInfo(dataFilePath_delete);
            if (sessionFileInfo != null)
            {
                deleteDataFileSize = sessionFileInfo.Length;
            }
        }

        logger.logDataOutputFinishProcessingDelete(deleteAXTableName, deletedRowsAffected, deleteDataFileSize);
    }

]]></Source>
			</Method>
			<Method>
				<Name>setCurrentSessions</Name>
				<Source><![CDATA[
    /// <summary>
    /// Sets the current sessions.
    /// </summary>
    /// <param name = "_currentSessions">The current sessions.</param>
    internal void setCurrentSessions(Set _currentSessions)
    {
        logger.setCurrentSessions(_currentSessions);
    }

]]></Source>
			</Method>
			<Method>
				<Name>setupFieldList</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal void setupFieldList(
        TableName _tableName,
        RetailConnSchedulerSubjobFieldList _fieldList)
    {
        // This method is empty on purpose in order to enable extensibility.
    }

]]></Source>
			</Method>
			<Method>
				<Name>preQuerySetup</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal QueryBuildDataSource preQuerySetup(TableId _mainTableId)
    {
        return q.addDataSource(_mainTableId);
    }

]]></Source>
			</Method>
			<Method>
				<Name>shouldUseFilteredRecordsTempTables</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal boolean shouldUseFilteredRecordsTempTables()
    {
        return this.paramSubjobContext().shouldUseFilteredRecordsTempTables();
    }

]]></Source>
			</Method>
			<Method>
				<Name>shoulAddQueryFilters</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal boolean shoulAddQueryFilters(TableName _subJobTableName)
    {
        // if the subjob's table source is a tempDB type table then no need to filter its content
        // as it is already filtered when the table is populated in the data translation class.
        return !RetailConnReplicationUtilities::isTableTempDB(_subJobTableName);
    }

]]></Source>
			</Method>
			<Method>
				<Name>setup</Name>
				<Source><![CDATA[
    internal void setup(RetailConnSubJobId subjobID)
    {
        q = new Query();
        q.allowCrossCompany(true);
        fieldTypeList = new List(Types::Enum);
        sourceFieldIDList = new List(Types::Integer);
        targetFieldNameList = new List(Types::String);
        constFieldValueList = new List(Types::String);

        RetailConnSchedulerSubjobTable subjob;

        select firstOnly AXTableName, FilterDuplicatePackageGenerationRecords
            from subjob
            where subjob.subJobId == subjobID;

        logger.logDataOutputStartWritingFile(subjob.AXTableName);

        TableId tid = tableName2id(subjob.AXTableName);
        QueryBuildDataSource dsMain = this.preQuerySetup(tid);
        
        // Define which sorting to be applied in the query generating the output.
        if (this.paramSubjobContext().paramDataSyncContext().paramIsSortCdxPackageByPrimaryIndexEnabled())
        {
            // Introduced initially for Eden data flattening, but it can leveraged for other scenarios.
            this.addSortByPrimaryIndex(dsMain);
        }
        else
        {
            filterDuplicateSubjobRecords = subjob.FilterDuplicatePackageGenerationRecords ? true : false;
            if (filterDuplicateSubjobRecords)
            {
                // Required to remove duplicated RecIds (rare case), which might or might not be the PK.
                subjobRecFieldId = fieldName2id(tid, 'RecId');
                dsMain.addSortField(subjobRecFieldId, SortOrder::Ascending);
            }
            else if (this.paramSubjobContext().paramDataSyncContext().paramIsPackageGenerationOrderByUniqueClusteredIndexEnabled())
            {
                // Introduced to reduce table fragmentation in channel database after a full sync.
                this.addSortByFields(dsMain);
            }
            else if (RetailCDXSkipDefaultSortingOfDataSyncOutputFlight::instance().isEnabled())
            {
                // If no intentional sorting is added, let SQL Server decide. If we don't set below, AOS kernel will pick the first index in metadata, which is not optimal.
                q.skipAutoOrderBy(true);
            }
        }

        q.clearAllFields();
        dsMain.fields().dynamic(NoYes::No);
        dsMain.fields().clearFieldList();

        if (this.shoulAddQueryFilters(subjob.AXTableName))
        {
            if (this.shouldUseFilteredRecordsTempTables())
            {
                this.joinFilteredRecordsTempTableToSourceTableDS(dsMain);
            }
            else
            {
                if (this.paramSubjobContext().paramTableFilterType() == RetailCDXDataDistributionTableFilterType::RangeBasedFilter)
                {
                    // if the table is range based then need to set the range values that are specified in the table distribution for the source table
                    this.addRangeValuesToSourceTableDS(dsMain);
                }

                if (!ctContext.paramIsInitSync())
                {
                    // in case of delta sync and for RangeBasedFilter and NoFilter type, needs to join main table with the change tracking result table directly
                    RetailCdxCsvDataOutput::joinChangeTrackingResultTableToSourceTableDS(dsMain);
                }

                // if no FilteredRecordsTempTable is used, then need to join with RetailTmpCDXTargetLegalEntity table to filter by target legal entities
                if (!RetailConnReplicationUtilities::isGlobalTable(subjob.AXTableName))
                {
                    RetailCdxCsvDataOutput::joinTargetLegalEntityTableToSourceTableDS(dsMain);
                }

                if (ctContext.paramIsDateFilterEnabled())
                {
                    // if DateFilterField is not empty, set the range value, only needs to filter when the table was not filtered before (channel specific filtering)
                    RetailCDXDateFilterField dateFilterField = RetailCDXDateFilterField::find(subjob.RetailConnChannelSchema, subjob.AXTableName);

                    if (dateFilterField.DateFilterField != '')
                    {
                        FieldId dateFilterFieldId = fieldName2Id(tid, dateFilterField.DateFilterField);
                        dsMain.addRange(dateFilterFieldId).value(strFmt('>%1', SysQuery::value(DateTimeUtil::getToday(DateTimeUtil::getUserPreferredTimeZone()) - 1)));
                        dsMain.addRange(dateFilterFieldId).value(SysQuery::value(DateTimeUtil::minValue())); // no need to filter a record if the its 'valid to' date is not set.
                    }
                }
            }
        }

        headerFieldList = dsMain.fields();

        int validTimeStateType = RetailConnReplicationUtilities::getValidTimeStateFieldType(subjob.AXTableName);

        switch (validTimeStateType)
        {
            case 1:
                q.validTimeStateDateRange(lowerDate, upperDate);
                break;

            case 2:
                q.validTimeStateDateTimeRange(lowerDateTime, upperDateTime);
                break;
        }

        RetailConnSchedulerSubjobFieldList fieldList;

        while select FromFieldName, ToFieldName, conversionType, conversionValue
            from fieldList
            order by fieldList.fromFieldName
            where fieldList.subjobId == subjobID
        {
            // Ignore DataAreaId as it will be added after the loop.
            if (fieldList.fromFieldName == RetailCDXConstants::DataAreaIdAXSideName)
            {
                continue;
            }

            FieldId fid = fieldName2id(tid, fieldList.fromFieldName);

            sourceFieldIDList.addEnd(fid);
            targetFieldNameList.addEnd(fieldList.toFieldName);

            if (fieldList.conversionType == RetailConnConversionType::Constant)
            {
                fieldTypeList.addEnd(RetailCDXChannelDataType::ConstValue);
                constFieldValueList.addEnd(fieldList.conversionValue);
            }
            else
            {
                DictField df = new DictField(tid, fid);
                headerFieldList.addField(fid);

                if (!fid)
                {
                    str errorMsg = strFmt("@Retail:RetailSchedulerSubjobFieldMissingError", subjob.AXTableName, fieldList.toFieldName);
                    throw Global::error(errorMsg);
                }

                switch (df.baseType())
                {
                    case Types::Integer:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Int);
                        break;

                    case Types::Enum:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Enum);
                        break;

                    case Types::Int64:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Long);
                        break;

                    case Types::String:
                    case Types::VarString:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::String);
                        break;

                    case Types::Real:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Decimal);
                        break;

                    case Types::Date:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Date);
                        break;

                    case Types::UtcDateTime:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::DateTime);
                        break;

                    case Types::Guid:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Guid);
                        break;

                    case Types::Container:
                        fieldTypeList.addEnd(RetailCDXChannelDataType::Binary);
                        break;

                    default:
                        throw Global::error(strFmt("Not supported data type: %1.%2", subjob.AXTableName, fieldList.toFieldName));
                }

                constFieldValueList.addEnd('');

                this.setupFieldList(subjob.AXTableName, fieldList);
            }
        }

        if (!RetailConnReplicationUtilities::isGlobalTable(subjob.AXTableName))
        {
            FieldId fid = fieldName2id(tid, RetailCDXConstants::DataAreaIdAXSideName);
            headerFieldList.addField(fid);
            sourceFieldIDList.addEnd(fid);
            targetFieldNameList.addEnd(RetailCDXConstants::DataAreaIdChannelSideName);

            if (singleTargetLE)
            {
                fieldTypeList.addEnd(RetailCDXChannelDataType::ConstValue);
                constFieldValueList.addEnd(singleTargetLE);
            }
            else
            {
                fieldTypeList.addEnd(RetailCDXChannelDataType::String);
                constFieldValueList.addEnd('');
            }
        }

        this.postSetup(subjob.AXTableName, headerFieldList);
    }

]]></Source>
			</Method>
			<Method>
				<Name>getQuery</Name>
				<Source><![CDATA[
    internal Query getQuery()
    {
        return q;
    }

]]></Source>
			</Method>
			<Method>
				<Name>postSetup</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal void postSetup(TableName _tableName, QueryBuildFieldList _queryBuildFieldList)
    {
        // This method is empty on purpose in order to enable extensibility.
    }

]]></Source>
			</Method>
			<Method>
				<Name>writeData</Name>
				<Source><![CDATA[
    /// <summary>
    /// Write data to file for subjob.
    /// </summary>
    /// <param name = "subjobID">Subjob ID.</param>
    public void writeData(RetailConnSubJobId subjobID)
    {
        this.setup(subjobID);
        this.output(subjobID);
    }

]]></Source>
			</Method>
			<Method>
				<Name>addSortByFields</Name>
				<Source><![CDATA[
    /// <summary>
    /// Adds sort by fields for main datasource.
    /// </summary>
    /// <param name = "dsMain">The main table datasource which will be added sort by fields.</param>
    internal void addSortByFields(QueryBuildDataSource dsMain)
    {
        TableId tableId = dsMain.table();
        DictTable mainTable = new DictTable(tableId);
        DictIndex sortIndex = new DictIndex(tableId, mainTable.clusterIndex());

        // if cluster index is not unique then sort by primary index, this is to align with the sorting order when applying the packages.
        if (sortIndex.allowDuplicates())
        {
            sortIndex = new DictIndex(tableId, mainTable.primaryIndex());
        }

        for (int indexCounter = 1; indexCounter <= sortIndex.numberOfFields(); indexCounter++)
        {
            FieldId indexFieldId = sortIndex.field(indexCounter);
            dsMain.addSortField(indexFieldId, SortOrder::Ascending);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>addSortByPrimaryIndex</Name>
				<Source><![CDATA[
    /// <summary>
    /// Adds sort by primary index fields for main datasource.
    /// </summary>
    /// <param name = "dsMain">The main table data source which will be sorted by primary index fields.</param>
    internal void addSortByPrimaryIndex(QueryBuildDataSource dsMain)
    {
        TableId tableId = dsMain.table();
        container pkFields = RetailConnReplicationUtilities::getAXPrimaryIndexColumnNames(tableId2Name(tableId));
        for (int i = 1; i <= conLen(pkFields); i++)
        {
            str fieldName = conPeek(pkFields, i);
            dsMain.addSortField(fieldName2Id(tableId, fieldname), SortOrder::Ascending);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>logSubjobSkipped</Name>
				<Source><![CDATA[
    /// <summary>
    /// Logs that a specific subjob has been skipped for package generation.
    /// </summary>
    internal void logSubjobSkipped(RetailConnSubJobId _subjobId)
    {
        logger.logDeleteDataFileSkipped(_subjobId);
        logger.logDataFileSkipped(_subjobId);
    }

]]></Source>
			</Method>
			<Method>
				<Name>joinFilteredRecordsTempTableToSourceTableDS</Name>
				<Source><![CDATA[
    private void joinFilteredRecordsTempTableToSourceTableDS(QueryBuildDataSource sourceTableDS)
    {
        QueryBuildDataSource filteredRecordsTempTableDS;
        TableId sourceTableId = sourceTableDS.table();

        if (ctContext.paramIsCacheBasedQueryEnabled())
        {
            if (ctContext.paramIsInitSync())
            {
                filteredRecordsTempTableDS = this.prepareFilteredRecordsCacheTempTableDS(sourceTableDS, tableNum(RetailTmpCDXDataDistributionFilteredRecords));
                filteredRecordsTempTableDS.addLink(fieldName2id(sourceTableId, 'RecId'), fieldNum(RetailTmpCDXDataDistributionFilteredRecords, RefRecId));
            }
            else
            {
                filteredRecordsTempTableDS = this.prepareFilteredRecordsCacheTempTableDS(sourceTableDS, tableNum(RetailTmpCDXDataDistributionDeltaSyncFilteredRecords));
                filteredRecordsTempTableDS.addRange(fieldNum(RetailTmpCDXDataDistributionDeltaSyncFilteredRecords, RecId)).value('((ChildNodeID = 0) || (ChildNodeID = -1))');
                filteredRecordsTempTableDS.addLink(fieldName2id(sourceTableId, 'RecId'), fieldNum(RetailTmpCDXDataDistributionDeltaSyncFilteredRecords, RefRecId));
            }
        }
        else
        {
            filteredRecordsTempTableDS = this.prepareFilteredRecordsCacheTempTableDS(sourceTableDS, tableNum(RetailCDXChangeRefTable2));
            filteredRecordsTempTableDS.addLink(fieldName2id(sourceTableId, 'RecId'), fieldNum(RetailCDXChangeRefTable2, RefRecId));
            QueryBuildRange range = filteredRecordsTempTableDS.addRange(fieldNum(RetailCDXChangeRefTable2, RefTableId));
            range.value(queryValue(sourceTableId));
        }

        // performance optimization
        Map sessionMap = this.ctContext.getSessions();
        if (!sessionMap.exists(RetailCDXDownloadSessionType::Default))
        {
            // if there is no Default type i.e. all datastores are using the DataFilter session type
            // then add range so that records that would be skipped are not returned from the database; as opposed to returning all results and skipping at data writing stage.
            filteredRecordsTempTableDS.addRange(this.paramSubJobContext().getSkipRecordFieldId()).value('0');
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>prepareFilteredRecordsCacheTempTableDS</Name>
				<Source><![CDATA[
    private QueryBuildDataSource prepareFilteredRecordsCacheTempTableDS(QueryBuildDataSource sourceTableDS, TableId filteredRecordsCacheTempTableId)
    {
        QueryBuildDataSource filteredRecordsCacheTempTableDS = sourceTableDS.addDataSource(filteredRecordsCacheTempTableId);
        
        filteredRecordsCacheTempTableDS.fields().dynamic(NoYes::No);
        filteredRecordsCacheTempTableDS.fields().clearFieldList();

        // determine what join to use based on skip record settings.
        if (this.paramSubJobContext().parmShouldFilterCdxEntityData())
        {
            // if the entity level record filtering is enabled for the subjob then set the join mode to inner join since the source table's datasource will be joined with
            // the table which contains distinct filtered records in the cache temp tables so as to get the skipRecord value of each row being synced.
            filteredRecordsCacheTempTableDS.fields().addField(this.paramSubJobContext().getSkipRecordFieldId());
            filteredRecordsCacheTempTableDS.joinMode(JoinMode::InnerJoin);
        }
        else
        {
            // if the entity level record filtering is enabled for the subjob then set the join mode to exist join since the source table's datasource only needs to check if the row
            // exists in the cache temp tables that contain the RecId of the rows that need to be synced.
            filteredRecordsCacheTempTableDS.joinMode(JoinMode::ExistsJoin);
        }

        filteredRecordsCacheTempTableDS.relations(false);

        return filteredRecordsCacheTempTableDS;
    }

]]></Source>
			</Method>
			<Method>
				<Name>joinChangeTrackingResultTableToSourceTableDS</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal static void joinChangeTrackingResultTableToSourceTableDS(QueryBuildDataSource sourceTableDS)
    {
        QueryBuildDataSource changeTrackingResultDS = sourceTableDS.addDataSource(tableNum(RetailCDXChangeRefTable1));
        changeTrackingResultDS.joinMode(JoinMode::ExistsJoin);
        changeTrackingResultDS.relations(false);
        TableId sourceTableId = sourceTableDS.table();
        changeTrackingResultDS.addLink(fieldName2Id(sourceTableId, 'RecId'), fieldNum(RetailCDXChangeRefTable1, RefRecID));
        QueryBuildRange range = changeTrackingResultDS.addRange(fieldNum(RetailCDXChangeRefTable1, RefTableID));
        range.value(queryValue(sourceTableId));
    }

]]></Source>
			</Method>
			<Method>
				<Name>joinTargetLegalEntityTableToSourceTableDS</Name>
				<Source><![CDATA[
    [Hookable(false)]
    internal static void joinTargetLegalEntityTableToSourceTableDS(QueryBuildDataSource sourceTableDS)
    {
        QueryBuildDataSource targetLegalEntityDS = sourceTableDS.addDataSource(tableNum(RetailTmpCDXTargetLegalEntity));
        targetLegalEntityDS.joinMode(JoinMode::ExistsJoin);
        targetLegalEntityDS.relations(false);
        targetLegalEntityDS.addLink(fieldName2Id(sourceTableDS.table(), RetailCDXConstants::DataAreaIdAXSideName), fieldNum(RetailTmpCDXTargetLegalEntity, TargetDataAreaId));
    }

]]></Source>
			</Method>
			<Method>
				<Name>addRangeValuesToSourceTableDS</Name>
				<Source><![CDATA[
    private void addRangeValuesToSourceTableDS(QueryBuildDataSource sourceTableDS)
    {
        RetailCDXDataDistributionQuery dataDistributionQuery;
        TableId sourceTableId = sourceTableDS.table();

        select firstonly IsGlobal, PackedQuery, QueryID
            from dataDistributionQuery
                where dataDistributionQuery.RetailConnChannelSchema == ctContext.getChannelSchema()
                    && dataDistributionQuery.RefTableID == sourceTableId
                    && dataDistributionQuery.IsCacheBasedQuery == NoYes::No;

        if (dataDistributionQuery)
        {
            Query dataSelectorQuery = new Query(dataDistributionQuery.packedQuery);
            QueryBuildDataSource baseTableDataSource = dataSelectorQuery.dataSourceNo(1);

            // range value in the packed query has datasource naming format like 't1.Product = 0', so we need to set the name here. And since there is only one table in the query it's always t1
            sourceTableDS.name('t1');

            for(int i = 1; i <= baseTableDataSource.rangeCount(); i++)
            {
                QueryBuildRange range = baseTableDataSource.range(i);
                sourceTableDS.addRange(range.field()).value(range.value());
            }
        }
    }

]]></Source>
			</Method>
		</Methods>
	</SourceCode>
</AxClass>