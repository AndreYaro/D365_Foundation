<?xml version="1.0" encoding="utf-8"?>
<AxClass xmlns:i="http://www.w3.org/2001/XMLSchema-instance">
	<Name>RetailCDXScheduleRunner</Name>
	<SourceCode>
		<Declaration><![CDATA[
/// <summary>
/// Retail CDX schedule runner.
/// </summary>
class RetailCDXScheduleRunner extends RunBaseBatch implements BatchRetryable
{
    BatchHeader batchHeader;
    RefRecId scheduleRecID;
    RetailCDXDataGroupRefRecId dataGroupRecID;
    RetailConnJobId jobID;
    RetailCDXRowVersion rowVersion;
    container targetDataStore;
    boolean deleteExistingData;
    guid correlationId;
    private RefRecId batchHeaderRecId;

    int parameterSet;
    private boolean isOneTimeBatch;

    const str RetailServiceAccount = 'RetailServiceAccount';
    private const int ParamRegularSyncConst = 0;
    private const int ParamFullSyncConst = 1;
    private const int ParamRerunConst = 2;

    // parameterSet:
    //    0: regular sync
    //    1: full sync
    //    2: re-run

    #define.CurrentVersion(1)

    #localmacro.CurrentList
        parameterSet,
        scheduleRecID,
        dataGroupRecID,
        jobID,
        rowVersion,
        targetDataStore,
        deleteExistingData
    #endmacro

    boolean taskExists;

    private RetailCDXScheduleLogger logger;

}
]]></Declaration>
		<Methods>
			<Method>
				<Name>allowSaveLast</Name>
				<Source><![CDATA[
    /// <summary>
    /// Returns if to allow save last.
    /// </summary>
    /// <returns>
    /// Returns if to allow save last.
    /// </returns>
    public boolean allowSaveLast()
    {
        return false;
    }

]]></Source>
			</Method>
			<Method>
				<Name>canGoBatchJournal</Name>
				<Source><![CDATA[
    /// <summary>
    ///    Indicates whether the class is shown in the list of <c>Journal</c> types.
    /// </summary>
    /// <returns>
    ///    true if the class is shown in the list of <c>Journal</c> types; otherwise, false.
    /// </returns>
    /// <remarks>
    ///    A class that can be used in a batch journal is a class where the same parameters can be used
    ///    repeatedly. The dialog box can be shown and the parameters can be changed, but parameters of some
    ///    classes might build on data that is only valid for a short time. Running a class two times with the
    ///    same parameters is not always possible. If the <c>RunBaseBatch.canGoBatch</c> method is false, this
    ///    method will not have any effect.
    /// </remarks>
    public boolean canGoBatchJournal()
    {
        return true;
    }

]]></Source>
			</Method>
			<Method>
				<Name>caption</Name>
				<Source><![CDATA[
    public ClassDescription caption()
    {
        RetailConnSchedule schedule;
        RetailCDXDataGroup dataGroup;
        RefRecId dataStoreRecID;

        select firstonly Name from schedule where schedule.RecId == scheduleRecID;

        switch (parameterSet)
        {
            case ParamRegularSyncConst:
                // regular upload sync, use schedule name
                if (schedule.ScheduleType == RetailCDXDownloadUpload::Upload)
                {
                    return schedule.Name;
                }
                else if (this.paramIsOneTimeBatch())
                {
                    return strFmt("@Retail:RetailCDXOneTimeIncrementalSyncText", schedule.Name);
                }
                else
                {
                    return strFmt("@Retail:RetailCDXIncrementalSyncText", schedule.Name);
                }

            case ParamFullSyncConst:
                if (conLen(targetDataStore) > 0)
                {
                    return strFmt("@Retail:RetailCdxFullSyncWithDb", schedule.Name, conLen(targetDataStore));
                }
                else
                {
                    select firstonly Name from dataGroup where dataGroup.RecId == dataGroupRecID;
                    // Full sync schedule on data group
                    return strFmt("@REX4160612", schedule.Name, dataGroup.Name);
                }

            case ParamRerunConst:
                if (conLen(targetDataStore) > 0)
                {
                    // Rerun scheduler job '%1' on data store '%2'
                    return strFmt("@Retail:RetailCdxDownloadSessionDataStoreRerunCaption", jobID, conLen(targetDataStore));
                }
                else
                {
                    select firstonly Name from dataGroup where dataGroup.RecId == dataGroupRecID;
                    // Rerun scheduler job '%1' on data group '%2'
                    return strFmt("@Retail:RetailCdxDownloadSessionRerunCaption", jobID, dataGroup.Name);
                }

            default:
                return schedule.Name;
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>pack</Name>
				<Source><![CDATA[
    public container pack()
    {
        return [#CurrentVersion,#CurrentList];
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramScheduleRecID</Name>
				<Source><![CDATA[
    /// <summary>
    /// Sets the value of schedule rec id.
    /// </summary>
    /// <param name="_scheduleRecID">
    /// The value of <c>ScheduleRecID</c>; optional.
    /// </param>
    /// <returns>
    /// Schedule id.
    /// </returns>
    public RefRecId paramScheduleRecID(RefRecId _scheduleRecID = scheduleRecID)
    {
        if (scheduleRecID != _scheduleRecID)
        {
            scheduleRecID = _scheduleRecID;
            parameterSet = ParamRegularSyncConst;
            this.validateParameters();
        }

        return scheduleRecID;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramParameterSet</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the parameter which signifies the type of the sync operation.
    /// </summary>
    /// <param name = "_parameterSet">The parameter set which signifies the sync operation type.</param>
    /// <returns>The value indicating the sync operation type.</returns>
    internal int paramParameterSet(int _parameterSet = parameterSet)
    {
        parameterSet = _parameterSet;
        return parameterSet;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramTargetDataStores</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the list of target dataStores.
    /// </summary>
    /// <param name = "_targetDataStores">The list of target dataStores.</param>
    /// <returns>The list of target dataStores.</returns>
    internal container paramTargetDataStores(container _targetDataStores = targetDataStore)
    {
        targetDataStore = _targetDataStores;
        return targetDataStore;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramJobId</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the job Id.
    /// </summary>
    /// <param name = "_jobId">The job Id.</param>
    /// <returns>The job Id.</returns>
    internal RetailConnJobId paramJobId(RetailConnJobId _jobId = jobId)
    {
        jobId = _jobId;
        return jobId;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramDeleteExistingData</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the flag indicating whether to delete existing data or not.
    /// </summary>
    /// <param name = "_deleteExistingData">The flag indicating whether to delete existing data or not.</param>
    /// <returns>True if existing data should be deleted; false otherwise.</returns>
    internal boolean paramDeleteExistingData(boolean _deleteExistingData = deleteExistingData)
    {
        deleteExistingData = _deleteExistingData;
        return deleteExistingData;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramRowVersion</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the row version.
    /// </summary>
    /// <param name = "_rowVersion">The row version.</param>
    /// <returns>The row version.</returns>
    internal RetailCDXRowVersion paramRowVersion(RetailCDXRowVersion _rowVersion = rowVersion)
    {
        rowVersion = _rowVersion;
        return rowVersion;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramCorrelationId</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the correlation Id.
    /// </summary>
    /// <param name = "_correlationId">The correlation Id.</param>
    /// <returns>The correlation Id.</returns>
    internal guid paramCorrelationId(guid _correlationId = correlationId)
    {
        correlationId = _correlationId;
        return correlationId;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramSchedulerBatchJobId</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the value of the scheduler's batch job record Id.
    /// </summary>
    /// <returns>
    /// The Scheduler's batch job record Id.
    /// </returns>
    internal RefRecId paramSchedulerBatchJobId()
    {
        return this.batchHeader ? this.batchHeader.parmBatchHeaderId() : this.batchHeaderRecId;
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramIsOneTimeBatch</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the one time batch job flag.
    /// </summary>
    /// <returns>
    /// True if the batch job is one time; false otherwise.
    /// </returns>
    internal boolean paramIsOneTimeBatch(boolean _isOneTimeBatch = isOneTimeBatch)
    {
        isOneTimeBatch = _isOneTimeBatch;
        return isOneTimeBatch;
    }

]]></Source>
			</Method>
			<Method>
				<Name>dialog</Name>
				<Source><![CDATA[
    /// <summary>
    /// Run base batch dialog.
    /// </summary>
    /// <returns>Dialog object.</returns>
    public Object dialog()
    {
        // Only show the full sync warning dialog if running full sync.
        if (parameterSet == ParamFullSyncConst)
        {
            DialogRunbase dialog = Dialog::newFormnameRunbase(formstr(RetailCDXFullSyncWarningDialog), this);
            dialog = this.dialogInternal(dialog);
            dialog.caption(this.caption());
            return dialog;
        }
        else // For Incremental Sync, use the default dialog.
        {
            return super();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>dialogPost</Name>
				<Source><![CDATA[
    /// <summary>
    /// Run base batch dialogPost.
    /// </summary>
    /// <returns>Dialog object.</returns>
    public void dialogPost(Object dialog)
    {
        super(dialog);

        DialogRunbase dialogRunbase = dialog;
        FormBuildDesign design = dialogRunbase.dialogForm().buildDesign();
        FormBuildFunctionButtonControl recurrenceButton = design.control('MnuItm_1');

        // if set to Rerun always diable Recurrence button since rerun is not allowed to be run recurrently;
        // and if feature flag is enabled and isOneTimeBatch flag is set to true, also disable Recurrence button
        if (parameterSet == ParamRerunConst || (!RetailCdxFeatureControl::isForceScheduleInBatchDisabled() && this.paramIsOneTimeBatch()))
        {
            if (recurrenceButton)
            {
                recurrenceButton.enabled(false);
            }
        }

        // expand the batch tab by default
        FormBuildTabPageControl batchTabPage = design.control('TabPg_1');

        if (batchTabPage)
        {
            batchTabPage.fastTabExpanded(FastTabExpanded::Yes);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>paramDataGroupRecID</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets or sets the value of the data group rec id.
    /// </summary>
    /// <param name="_dataGroupRecID">
    /// The value of <c>RetailCDXDataGroupRefRecId</c>; optional.
    /// </param>
    /// <returns>
    /// The data group id.
    /// </returns>
    public RetailCDXDataGroupRefRecId paramDataGroupRecID(RefRecId _dataGroupRecID = dataGroupRecID)
    {
        if (dataGroupRecID != _dataGroupRecID)
        {
            dataGroupRecID = _dataGroupRecID;
            this.validateParameters();
        }

        return dataGroupRecID;
    }

]]></Source>
			</Method>
			<Method>
				<Name>processFullSync</Name>
				<Source><![CDATA[
    private void processFullSync()
    {
        RetailCDXDataGroup dataGroup;
        RetailConnScheduleJobMapping scheduleJob;
        RetailConnSchedulerJobTable job;
        RetailCDXRowVersion lastSyncVer;

        select firstonly RecId, ChannelSchema from dataGroup
                        where dataGroup.RecId == dataGroupRecID;

        while select RecId, Enabled from scheduleJob
                where scheduleJob.ScheduleRecId == scheduleRecID
            join JobId, IsUpload from job
                where scheduleJob.SchedulerJobId == job.JobId
                    && dataGroup.ChannelSchema == job.RetailConnChannelSchema
        {
            if (scheduleJob.Enabled == NoYes::Yes)
            {
                lastSyncVer = -1;

                if (!job.IsUpload)
                {
                    this.runDownloadTask(
                        dataGroup.RecId,
                        job.JobId,
                        lastSyncVer,
                        targetDataStore,
                        deleteExistingData);

                    this.taskExists = true;
                }
            }
            else
            {
                logger.logCDXScheduleSkippedDisabledJob();
            }
        }

        if (this.taskExists)
        {
            // write channel DB
            this.runDataWritingBatchJob(this.dataGroupRecID, this.targetDataStore);
        }
        else
        {
            logger.logCDXScheduleValidJobsNotFound();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>processRegular</Name>
				<Source><![CDATA[
    private void processRegular()
    {
        RetailCDXDataGroup dataGroup;
        RetailCDXScheduleDataGroup scheduleDataGroup;
        RetailConnScheduleJobMapping scheduleJob;
        RetailConnSchedulerJobTable job;
        RetailCDXRowVersion lastSyncVer;

        boolean scheduleContainsUploadJobs = false;

        while select RecId from dataGroup
            join RecId from scheduleDataGroup
                where dataGroup.RecId == scheduleDataGroup.DataGroup
                    && scheduleDataGroup.Schedule == scheduleRecID
            join RecId, Enabled from scheduleJob
                where scheduleJob.ScheduleRecId == scheduleRecID
            join JobId, IsUpload from job
                where scheduleJob.SchedulerJobId == job.JobId
                    && dataGroup.ChannelSchema == job.RetailConnChannelSchema
        {
            if (scheduleJob.Enabled == NoYes::Yes)
            {
                lastSyncVer = RetailCDXDataSyncRowVersion::getRowVersion(dataGroup.RecId, job.JobId);

                if (job.IsUpload)
                {
                    if (!this.isRetailCdxUploadSessionParallelProcessingEnabled())
                    {
                        // if parallel processing is not enabled keep adding taks per datagroup per job
                        // otherwise create several concurrent tasks on the schedule level - this allows multiple batch tasks
                        // to process all sessions corresponding to that schedule in parallel.
                        this.runUploadTask(dataGroup.RecId, job.JobId);
                        this.taskExists = true;
                    }

                    scheduleContainsUploadJobs = true;
                }
                else
                {
                    if (RetailCDXDataGroup::checkIfAnyChannelExists(dataGroup.RecId))
                    {
                        this.runDownloadTask(
                            dataGroup.RecId,
                            job.JobId,
                            lastSyncVer,
                            targetDataStore);

                        this.taskExists = true;
                    }
                }
            }
            else
            {
                logger.logCDXScheduleSkippedDisabledJob();
            }
        }

        // if parallel processing is enabled create the concurrent tasks on the schedule level.
        if (this.isRetailCdxUploadSessionParallelProcessingEnabled() && scheduleContainsUploadJobs)
        {
            this.runConcurrentUploadTask();
            this.taskExists = true;
        }

        if (this.taskExists)
        {
            while select DataGroup from scheduleDataGroup
              where scheduleDataGroup.Schedule == scheduleRecID
            {
                // write channel DB
                this.runDataWritingBatchJob(scheduleDataGroup.DataGroup);
            }
        }
        else
        {
            logger.logCDXScheduleValidJobsNotFound();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>processRerun</Name>
				<Source><![CDATA[
    private void processRerun()
    {
        RetailConnScheduleJobMapping scheduleJob;
        RetailConnSchedulerJobTable job;

        select firstonly Enabled from scheduleJob
            where scheduleJob.ScheduleRecId == scheduleRecID
                && scheduleJob.SchedulerJobId == jobID;

        select firstonly IsUpload from job
            where job.JobId == jobID;

        if (scheduleJob.Enabled == NoYes::Yes && !job.IsUpload)
        {
            this.runDownloadTask(
                dataGroupRecID,
                jobID,
                rowVersion,
                targetDataStore);

            this.taskExists = true;

            // write channel DB
            this.runDataWritingBatchJob(this.dataGroupRecID, this.targetDataStore);
        }

        if (!this.taskExists)
        {
            logger.logCDXScheduleValidJobsNotFound();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>run</Name>
				<Source><![CDATA[
    public void run()
    {
        System.Exception ex;
        container result;

        try
        {
            logger.logCDXSchedulingStart();

            // If the current user has proper permissions, run with that user.
            if (RetailCdxPreAssertRetailServiceAccountFlight::instance().isEnabled())
            {
                if (RetailCDXDataSync::GetFullReadAccessPermissionError(curUserId()) == '')
                {
                    result = RetailCDXScheduleRunner::runImpl([this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                }
                else
                {
                    if (!SysUserInfo::find(RetailServiceAccount))
                    {
                        warning("@Retail:RetailServiceAccountNotExist");
                        // If RetailServiceAccount doesn't exist, run with current user.
                        result = RetailCDXScheduleRunner::runImpl([this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                    }
                    else
                    {
                        if (RetailCdxRunAsRetailServiceAccountFlight::instance().isEnabled() &&
                            RetailCDXDataSync::GetFullReadAccessPermissionError(RetailServiceAccount) == '')
                        {
                            try
                            {
                                RunAsPermission permission = new RunAsPermission(RetailServiceAccount);
                                permission.assert();

                                result = runAs(RetailServiceAccount,
                                               classnum(RetailCDXScheduleRunner),
                                               staticMethodStr(RetailCDXScheduleRunner, runImpl),
                                               [this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                            }
                            finally
                            {
                                CodeAccessPermission::revertAssert();
                            }
                        }
                        else
                        {
                            // if both users fail assert, use curUser which can be fixed
                            result = RetailCDXScheduleRunner::runImpl([this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                        }
                    }
                }
            }
            // Previous logic of always impersonating
            else
            {
                // If the RetailServiceAccount user exists, set the batch executor.
                if (RetailCdxRunAsRetailServiceAccountFlight::instance().isEnabled() && SysUserInfo::find(RetailServiceAccount))
                {
                    try
                    {
                        RunAsPermission permission = new RunAsPermission(RetailServiceAccount);
                        permission.assert();

                        result = runAs(RetailServiceAccount,
                           classnum(RetailCDXScheduleRunner),
                           staticMethodStr(RetailCDXScheduleRunner, runImpl),
                           [this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                    }
                    finally
                    {
                        CodeAccessPermission::revertAssert();
                    }
                }
                else
                {
                    if (!SysUserInfo::find(RetailServiceAccount))
                    {
                        warning("@Retail:RetailServiceAccountNotExist");
                    }

                    result = RetailCDXScheduleRunner::runImpl([this.pack(), this.isInBatch(), this.paramCorrelationId(), this.parmCurrentBatch()]);
                }
            }

            this.batchHeaderRecId = conPeek(result, 1);
            this.taskExists = conPeek(result, 2);
        }
        catch (ex)
        {
            logger.logCDXSchedulingFailure(ex);
            throw error(ex.ToString());
        }
        finally
        {
            logger.logCDXSchedulingStop(ex);
        }

    }

]]></Source>
			</Method>
			<Method>
				<Name>runImpl</Name>
				<Source><![CDATA[
    internal static container runImpl(container _parm)
    {
        RetailCDXScheduleRunner  retailCDXScheduleRunner = new RetailCDXScheduleRunner();
        RetailCDXDataSync::AssertUserHasFullReadAccessPermission(curUserId());

        retailCDXScheduleRunner.unpack(conPeek(_parm, 1));
        retailCDXScheduleRunner.parmInBatch(conPeek(_parm, 2));
        retailCDXScheduleRunner.paramCorrelationId(conPeek(_parm, 3));
        retailCDXScheduleRunner.parmCurrentBatch(conPeek(_parm, 4));
        retailCDXScheduleRunner.validateParameters();

        RetailConnSchedule schedule;

        select firstonly Name, Active from schedule
            where schedule.RecId == retailCDXScheduleRunner.paramScheduleRecID();

        if (schedule.Active == NoYes::No)
        {
            Global::warning(strFmt("@REX4160596", schedule.Name));
            return [(retailCDXScheduleRunner.batchHeader ? retailCDXScheduleRunner.batchHeader.parmBatchHeaderId() : 0), retailCDXScheduleRunner.taskExists];
        }

        switch (retailCDXScheduleRunner.paramParameterSet())
        {
            case ParamRegularSyncConst: // regular
                retailCDXScheduleRunner.processRegular();
                break;
            case ParamFullSyncConst: // full sync
                retailCDXScheduleRunner.processFullSync();
                break;
            case ParamRerunConst: // rerun
                retailCDXScheduleRunner.processRerun();
                break;

            default:
                break;
        }

        if (RetailCdxParallelUploadSessionSkipNullExceptionFlight::instance().isEnabled())
        {
            if (retailCDXScheduleRunner.taskExists && retailCDXScheduleRunner.batchHeader)
            {
                if (retailCDXScheduleRunner.isInBatch())
                {
                    retailCDXScheduleRunner.saveBatchHeaderWithRetry();
                }
            }
            else
            {
                select firstonly Name from schedule where schedule.RecId == retailCDXScheduleRunner.paramScheduleRecID();
                // Schedule %1 has no associated channel database group, or no channel schema, or no enabled job.
                Global::warning(strFmt("@Retail:RetailCdxScheduleMissingGroupOrJobOrSchemaError", schedule.Name));
            }
        }
        else
        {
            if (retailCDXScheduleRunner.taskExists)
            {
                if (retailCDXScheduleRunner.isInBatch())
                {
                    retailCDXScheduleRunner.saveBatchHeaderWithRetry();
                }
            }
            else
            {
                select firstonly Name from schedule where schedule.RecId == retailCDXScheduleRunner.paramScheduleRecID();
                // Schedule %1 has no associated channel database group, or no channel schema, or no enabled job.
                Global::warning(strFmt("@Retail:RetailCdxScheduleMissingGroupOrJobOrSchemaError", schedule.Name));
            }
        }

        return [(retailCDXScheduleRunner.batchHeader ? retailCDXScheduleRunner.batchHeader.parmBatchHeaderId() : 0), retailCDXScheduleRunner.taskExists];
    }

]]></Source>
			</Method>
			<Method>
				<Name>runDownloadTask</Name>
				<Source><![CDATA[
    private void runDownloadTask(RefRecId _dataGroupRecID, RetailConnJobId _jobID, RetailCDXRowVersion _lastSyncVer, container _targetDataStore = conNull(), boolean _deleteExistingData = false, boolean _readingOnly = false)
    {
        RetailCDXScheduleRunner::validateDataGroup(_dataGroupRecID);

        // read

        if (this.isInBatch())
        {
            RetailCDXJobRunner jobRunner = new RetailCDXJobRunner();
            jobRunner.paramDataGroupRecID(_dataGroupRecID);
            jobRunner.paramJobID(_jobID);
            jobRunner.paramLastSyncVer(_lastSyncVer);
            jobRunner.paramScheduleRecID(scheduleRecID);
            jobRunner.paramTargetDataStore(_targetDataStore);
            jobRunner.paramDeleteExistingData(_deleteExistingData);
            jobRunner.paramReadingOnly(_readingOnly);
            jobRunner.paramCorrelationId(this.correlationId);
            jobRunner.paramBatchJobId(this.parmCurrentBatch().BatchJobId);

            // Schedule for later run
            if (!batchHeader)
            {
                batchHeader = BatchHeader::construct(this.parmCurrentBatch().BatchJobId);
            }

            batchHeader.addRuntimeTask(jobRunner, this.parmCurrentBatch().RecId);
            logger.logCDXScheduleQueuedJobRunnerAsBatchTask(jobRunner);
        }
        else
        {
            container cdxJobParameters = [scheduleRecID, _dataGroupRecID, _jobID, _lastSyncVer, _targetDataStore, _deleteExistingData, _readingOnly, this.correlationId];
            logger.logCDXScheduleTriggeredDownloadSourceProcessingInProc(cdxJobParameters);
            RetailCDXDataSync::sync(cdxJobParameters);
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>runDataWritingBatchJob</Name>
				<Source><![CDATA[
    private void runDataWritingBatchJob(RefRecId _dataGroupRecID, container _targetDataStore = conNull())
    {
        RetailConnDatabaseProfile dataStore;
        RetailCdxChannelDbDirectAccess writeRunner;

        if (conLen (_targetDataStore) > 0)
        {
            for (int i = 1; i <= conLen(_targetDataStore); ++i)
            {
                RetailCDXDataStoreRefRecId dataStoreRecID = conPeek(_targetDataStore, i);

                if (dataStoreRecID)
                {
                    select firstonly Name, ConnectionString, DataStoreType, DataWritingBatchJob
                       from dataStore
                       where dataStore.RecId == dataStoreRecID;

                    if (dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase && dataStore.isUsingAxHostedCdxForUploadSessionPackageGeneration())
                    {
                        this.createDataWritingBatchJob(dataStore);
                    }
                }
            }
        }
        else
        {
            while select Name, RecId, DataWritingBatchJob, ConnectionString
                from dataStore
                where dataStore.DataGroup == _dataGroupRecID
                   && dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase
            {
                if (dataStore.isUsingAxHostedCdxForUploadSessionPackageGeneration())
                {
                    this.createDataWritingBatchJob(dataStore);
                }
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>createDataWritingBatch</Name>
				<Source><![CDATA[
    private static void createDataWritingBatch(RecId _dataStoreRecId)
    {
        ttsbegin;

        RetailConnDatabaseProfile dataStore;
        select forupdate firstonly dataStore where dataStore.RecId == _dataStoreRecId;

        // if the datastore exists create the corresponding data writing batch job.
        if (dataStore.RecId)
        {
            // create batch job, run every 3 min
            RetailCdxChannelDbDirectAccess writeRunner = RetailCdxChannelDbDirectAccess::constructDataWritingRunner(dataStore.RecId);

            BatchHeader batchHeaderDataWriting = BatchHeader::construct();
            batchHeaderDataWriting.addTask(writeRunner);

            SysRecurrenceData recur = SysRecurrence::defaultRecurrence();
            recur = SysRecurrence::setRecurrenceNoEnd(recur);
            recur = SysRecurrence::setRecurrenceUnit(recur, SysRecurrenceUnit::Minute, 3);
            batchHeaderDataWriting.parmRecurrenceData(recur);
            batchHeaderDataWriting.save();

            // update datawriting batch job ID of the current data store.
            dataStore.DataWritingBatchJob = batchHeaderDataWriting.parmBatchHeaderId();
            dataStore.update();
        }

        ttscommit;
    }

]]></Source>
			</Method>
			<Method>
				<Name>createDataWritingBatchJob</Name>
				<Source><![CDATA[
    internal void createDataWritingBatchJob(RetailConnDatabaseProfile _dataStore)
    {
        BatchHeader batchHeaderDataWriting;

        Microsoft.Dynamics.Ax.Xpp.ErrorException xppEx;

        try
        {
            boolean shouldCreateNewDataWritingBatchjob = false;
            BatchJob batchJobTable;

            // check if this batch job actually exists.
            select firstonly RecId from batchJobTable
                    where batchJobTable.RecId == _dataStore.DataWritingBatchJob;

            if (batchJobTable)
            {
                SysUserInfo userInfo = SysUserInfo::find(batchJobTable.ExecutingBy);

                if (userInfo.RecId != 0)
                {
                    batchHeaderDataWriting = BatchHeader::construct(batchJobTable.RecId);
                    if (batchJobTable.Status == BatchStatus::Canceled || batchJobTable.Status == BatchStatus::Hold)
                    {
                        logger.logDataWritingBatchStatusWarning(_dataStore, batchJobTable);
                    }

                    logger.logReusedExistingDataWiritingBatch(_dataStore, batchHeaderDataWriting);
                }
                else
                {
                    logger.logDataWritingBatchJobUserIsInvalid(_dataStore);
                    shouldCreateNewDataWritingBatchjob = true;
                }
            }
            else
            {
                if (_dataStore.DataWritingBatchJob != 0)
                {
                    // log that the batch DataWritingBatchJob is not found.
                    logger.logDataWritingBatchJobNotFound(_dataStore);
                }

                shouldCreateNewDataWritingBatchjob = true;
            }

            if (shouldCreateNewDataWritingBatchjob)
            {
                ttsbegin;

                int64 previousDataWritingBatchJob = _dataStore.DataWritingBatchJob;

                // delete existing to make sure invalid batch is removed from the system.
                delete_from batchJobTable where batchJobTable.RecId == _dataStore.DataWritingBatchJob;

                // if the RetailServiceAccount user exists set it as the data writing batch's executor. This user is now guaranteed to be availabe in the system.
                UserId batchExecutorUserId = SysUserInfo::find(RetailServiceAccount) ? RetailServiceAccount : curUserId();
                try
                {
                    // impersonate as the batchExecutor to make sure the datawriting batch executor is set to the value in batchExecutorUserId
                    RunAsPermission permission = new RunAsPermission(batchExecutorUserId);
                    permission.assert();
                    runAs(batchExecutorUserId,
                          classnum(RetailCDXScheduleRunner),
                          staticMethodStr(RetailCDXScheduleRunner, createDataWritingBatch),
                          [_dataStore.RecId]);
                }
                finally
                {
                    CodeAccessPermission::revertAssert();
                }

                ttscommit;

                _dataStore.reread();

                if (_dataStore.RecId != 0 && _dataStore.DataWritingBatchJob != previousDataWritingBatchJob)
                {
                    batchHeaderDataWriting = BatchHeader::construct(_dataStore.DataWritingBatchJob);
                    logger.logCreatedDataWritingBatchJob(_dataStore, batchHeaderDataWriting);
                }
                else
                {
                    // if new data writing batch was not created, then log failure event.
                    // this captures the scenario where data writing batch job creation in createDataWritingBatch is skipped because the datastore was not found when selected in createDataWritingBatch.
                    logger.logCDXScheduleDataWritingBatchCreationFailure(_dataStore, batchHeaderDataWriting, new System.Exception('Data writing batch creation skipped because the datastore was not found.'));
                }
            }
        }
        catch (xppEx)
        {
            logger.logCDXScheduleDataWritingBatchCreationFailure(_dataStore, batchHeaderDataWriting, xppEx);  //do not throw as it could affect other datastores which could work properly.
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>addUploadRuntimeTask</Name>
				<Source><![CDATA[
    // Declared to enable extensibility.
    protected void addUploadRuntimeTask(RetailCDXDataUpload _uploader, Batch _scheduleRunnerBatch)
    {
        batchHeader.addRuntimeTask(_uploader, _scheduleRunnerBatch.RecId);
    }

]]></Source>
			</Method>
			<Method>
				<Name>runUploadTask</Name>
				<Source><![CDATA[
    private void runUploadTask(RefRecId _dataGroupRecID, RetailConnJobId _jobID)
    {
        RetailCDXScheduleRunner::validateDataGroup(_dataGroupRecID);

        // Perform upload task.
        RetailConnChannelSchema channelSchema;
        RetailConnSchedulerJobTable schedulerJob;
        RetailCdxChannelDbDirectAccess readRunner;

        select firstonly DataUploadClass
        from channelSchema
            exists join schedulerJob
                where channelSchema.RecId == schedulerJob.RetailConnChannelSchema
                   && schedulerJob.JobId == _jobID;

        ClassId classId = className2Id(channelSchema.DataUploadClass);

        if (!classId)
        {
            // class does not exist
            throw Global::error(strFmt("@SYS4973", channelSchema.DataUploadClass));
        }

        DictClass dc = new DictClass(classId);
        RetailCDXDataUpload uploader = dc.makeObject();
        uploader.paramDataGroupRecID(_dataGroupRecID);
        uploader.paramJobId(_jobID);
        uploader.paramLastSyncVer(0); // not used
        uploader.paramScheduleRecID(scheduleRecID);
        uploader.paramCorrelationId(this.paramCorrelationId());
        uploader.paramBatchJobId(this.parmCurrentBatch().BatchJobId);

        if (this.isInBatch())
        {
            if (!batchHeader)
            {
                batchHeader = BatchHeader::construct(this.parmCurrentBatch().BatchJobId);
            }
            this.addUploadRuntimeTask(uploader, this.parmCurrentBatch());
            logger.logCDXScheduleQueuedUploadTargetWriterAsBatchTask(uploader);
        }

        RetailConnDatabaseProfile dataStore;

        // create reading tasks
        while select ConnectionString, RecId
            from dataStore
            where dataStore.DataGroup == _dataGroupRecID
                && dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase
        {
            readRunner = RetailCdxChannelDbDirectAccess::constructDataReadingRunner(_jobID, dataStore.RecId, scheduleRecID);
            readRunner.paramCorrelationId(this.paramCorrelationId());

            if (this.isInBatch())
            {
                // If data store connection string exists, it is cloud channel database.
                if (dataStore.isUsingAxHostedCdxForUploadSessionPackageGeneration())
                {
                    batchHeader.addRuntimeTask(readRunner, this.parmCurrentBatch().RecId);
                    batchHeader.addDependency(uploader, readRunner, BatchDependencyStatus::FinishedOrError);
                    logger.logCDXScheduleQueuedUploadSourceReaderAsBatchTask(readRunner);
                }
            }
            else
            {
                // If data store is store system channel database, AX only upload from blob storage to AXDB.
                if (dataStore.isUsingAxHostedCdxForUploadSessionPackageGeneration())
                {
                    logger.logCDXScheduleTriggeredUploadSourceReaderInProc(readRunner);
                    readRunner.runOperation();
                }
            }
        }

        if (!this.isInBatch())
        {
            logger.logCDXScheduleTriggeredUploadTargetWriterInProc(uploader);
            uploader.runOperation();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>runConcurrentUploadTask</Name>
				<Source><![CDATA[
    private void runConcurrentUploadTask()
    {
        RetailCDXScheduleDataGroup scheduleDataGroup;
        RetailConnScheduleJobMapping scheduleJobMapping;
        RetailConnSchedulerJobTable schedulerJob;

        RetailConnDatabaseProfile dataStore;

        List readRunnerTaskList = new List(Types::Class);

        // create reading tasks
        while select ConnectionString, RecId from dataStore
                where dataStore.DataStoreType == RetailCDXDataStoreType::ChannelDatabase
            join scheduleDataGroup
                where scheduleDataGroup.DataGroup == dataStore.DataGroup
                    && scheduleDataGroup.Schedule == this.scheduleRecID
            join scheduleJobMapping
                where scheduleJobMapping.ScheduleRecId == scheduleDataGroup.schedule
            join jobId from schedulerJob
                where schedulerJob.jobId == scheduleJobMapping.SchedulerJobId
                   && schedulerJob.IsUpload == NoYes::Yes
                
        {
            RetailCdxChannelDbDirectAccess readRunner = RetailCdxChannelDbDirectAccess::constructDataReadingRunner(schedulerJob.jobId, dataStore.RecId, scheduleRecID);
            readRunner.paramCorrelationId(this.paramCorrelationId());

            if (dataStore.isUsingAxHostedCdxForUploadSessionPackageGeneration())
            {
                if (this.isInBatch())
                {
                    if (!batchHeader)
                    {
                        batchHeader = BatchHeader::construct(this.parmCurrentBatch().BatchJobId);
                    }

                    readRunnerTaskList.addEnd(readRunner);
                    batchHeader.addRuntimeTask(readRunner, this.parmCurrentBatch().RecId);
                    logger.logCDXScheduleQueuedUploadSourceReaderAsBatchTask(readRunner);
                }
                else
                {
                    logger.logCDXScheduleTriggeredUploadSourceReaderInProc(readRunner);
                    readRunner.runOperation();
                }
            }
        }

        // create multiple batch task for processing sessions in parallel.
        RetailConnChannelSchema channelSchema;

        while select DataUploadClass, RecId from channelSchema
            exists join schedulerJob
                where channelSchema.RecId == schedulerJob.RetailConnChannelSchema
            exists join scheduleJobMapping
               where scheduleJobMapping.SchedulerJobId == schedulerJob.jobId
                  && scheduleJobMapping.ScheduleRecId == this.scheduleRecID
        {
            if (channelSchema.DataUploadClass == classStr(RetailCDXDataUpload_AX7))
            {
                int sessionCount = RetailCDXUploadSessionTracker::populateUploadSessions(this.paramCorrelationId());

                for (int i=0; i < this.getNumberOfUploadBatchTasksRequired(sessionCount); i++)
                {
                    // schedule multiple task to process upload sessions corresponding to this schedule concurrently.
                    RetailCDXDataUpload uploader = new RetailCDXDataUpload_AX7();
                    uploader.paramDataGroupRecID(0); // we will process session from all data groups in the schedule
                    uploader.paramJobId('');         // we will process sessions from all jobs in the schedule
                    uploader.paramLastSyncVer(0);    // this is not used for upload jobs
                    uploader.paramScheduleRecID(this.scheduleRecID);
                    uploader.paramCorrelationId(this.paramCorrelationId());
                    uploader.paramBatchJobId(this.parmCurrentBatch().BatchJobId);

                    if (this.isInBatch())
                    {
                        if (!batchHeader)
                        {
                            batchHeader = BatchHeader::construct(this.parmCurrentBatch().BatchJobId);
                        }
                        this.addUploadRuntimeTask(uploader, this.parmCurrentBatch());

                        ListIterator readRunnerIterator =  new ListIterator(readRunnerTaskList);
                        while (readRunnerIterator.more())
                        {
                            batchHeader.addDependency(uploader, readRunnerIterator.value(), BatchDependencyStatus::FinishedOrError);
                            readRunnerIterator.next();
                        }

                        logger.logCDXScheduleQueuedUploadTargetWriterAsBatchTask(uploader);
                    }
                    else
                    {
                        logger.logCDXScheduleTriggeredUploadTargetWriterInProc(uploader);
                        uploader.runOperation();
                        break;
                    }
                }
            }
            else
            {
                // if data upload class is not the default use single task per datagroup per job
                // as the class may not support concurrent processing.
                ClassId classId = className2Id(channelSchema.DataUploadClass);

                if (!classId)
                {
                    // class does not exist
                    throw Global::error(strFmt("@SYS4973", channelSchema.DataUploadClass));
                }

                RetailCDXDataGroup dataGroup;
                RetailCDXScheduleDataGroup retailCDXScheduleDataGroup;
                RetailConnScheduleJobMapping scheduleJob;
                RetailConnSchedulerJobTable job;

                while select RecId from dataGroup
                        where dataGroup.ChannelSchema == channelSchema.RecId
                    join RecId from retailCDXScheduleDataGroup
                        where dataGroup.RecId == retailCDXScheduleDataGroup.DataGroup
                    join RecId, Enabled from scheduleJob
                        where retailCDXScheduleDataGroup.Schedule == scheduleJob.ScheduleRecId
                           && scheduleJob.ScheduleRecId == scheduleRecID
                    join JobId from job
                        where job.IsUpload == NoYes::Yes
                           && job.JobId == scheduleJob.SchedulerJobId
                           && job.RetailConnChannelSchema == dataGroup.ChannelSchema
                {
                    DictClass dc = new DictClass(classId);
                    RetailCDXDataUpload uploader = dc.makeObject();
                    uploader.paramDataGroupRecID(dataGroup.RecId);
                    uploader.paramJobId(job.JobId);
                    uploader.paramLastSyncVer(0);
                    uploader.paramScheduleRecID(scheduleRecID);
                    uploader.paramCorrelationId(this.paramCorrelationId());
                    uploader.paramBatchJobId(this.parmCurrentBatch().BatchJobId);

                    if (this.isInBatch())
                    {
                        if (!batchHeader)
                        {
                            batchHeader = BatchHeader::construct(this.parmCurrentBatch().BatchJobId);
                        }
                        this.addUploadRuntimeTask(uploader, this.parmCurrentBatch());
                        
                        ListIterator readRunnerIterator =  new ListIterator(readRunnerTaskList);
                        while (readRunnerIterator.more())
                        {
                            batchHeader.addDependency(uploader, readRunnerIterator.value(), BatchDependencyStatus::FinishedOrError);
                            readRunnerIterator.next();
                        }

                        logger.logCDXScheduleQueuedUploadTargetWriterAsBatchTask(uploader);
                    }
                    else
                    {
                        logger.logCDXScheduleTriggeredUploadTargetWriterInProc(uploader);
                        uploader.runOperation();
                    }
                }
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>isRetailCdxUploadSessionParallelProcessingEnabled</Name>
				<Source><![CDATA[
    internal boolean isRetailCdxUploadSessionParallelProcessingEnabled()
    {
        return RetailCdxUploadSessionParallelProcessingV2Flight::instance().isEnabled();
    }

]]></Source>
			</Method>
			<Method>
				<Name>setFullSync</Name>
				<Source><![CDATA[
    /// <summary>
    /// Sets the full sync.
    /// </summary>
    /// <param name="_scheduleRecID">
    /// Schedule rec id.
    /// </param>
    /// <param name="_dataGroupRecID">
    /// Data group rec id.
    /// </param>
    /// <param name="_targetDataStore">
    /// Target data store.
    /// </param>
    /// <param name="_deleteExistingData">
    /// Flag indicates if deleting existing data.
    /// </param>
    public void setFullSync(RefRecId _scheduleRecID, RefRecId _dataGroupRecID, container _targetDataStore, boolean _deleteExistingData = true)
    {
        parameterSet = ParamFullSyncConst;

        scheduleRecID = _scheduleRecID;
        dataGroupRecID = _dataGroupRecID;
        targetDataStore = _targetDataStore;
        deleteExistingData = _deleteExistingData;

        this.validateParameters();
    }

]]></Source>
			</Method>
			<Method>
				<Name>setRerun</Name>
				<Source><![CDATA[
    /// <summary>
    /// Sets the session for rerun.
    /// </summary>
    /// <param name="_scheduleRecID">
    /// Schedule rec id.
    /// </param>
    /// <param name="_dataGroupRecID">
    /// Data group rec id.
    /// </param>
    /// <param name="_jobID">
    /// Job id.
    /// </param>
    /// <param name="_rowVersion">
    /// Row version.
    /// </param>
    /// <param name="_targetDataStore">
    /// Target data store.
    /// </param>
    public void setRerun(RefRecId _scheduleRecID, RefRecId _dataGroupRecID, RetailConnJobId _jobID, RetailCDXRowVersion _rowVersion, container _targetDataStore)
    {
        parameterSet = ParamRerunConst;

        scheduleRecID = _scheduleRecID;
        dataGroupRecID = _dataGroupRecID;
        jobID = _jobID;
        rowVersion = _rowVersion;
        targetDataStore = _targetDataStore;

        this.validateParameters();
    }

]]></Source>
			</Method>
			<Method>
				<Name>unpack</Name>
				<Source><![CDATA[
    public boolean unpack(container _packedClass)
    {
        Integer version = conPeek(_packedClass,1);

        switch (version)
        {
            case #CurrentVersion:
                [version, #CurrentList] = _packedClass;
                break;
            default:
                return false;
        }

        return true;
    }

]]></Source>
			</Method>
			<Method>
				<Name>validateParameters</Name>
				<Source><![CDATA[
    private void validateParameters()
    {
        RetailConnSchedule schedule;

        select firstonly Name, ScheduleType, RecId from schedule
            where schedule.RecId == scheduleRecID;

        if (!schedule)
        {
            // schedule does not exist
            throw Global::error(strFmt("@REX4160597", scheduleRecID));
        }

        // Upload schedule: does not support full sync/rerun here. must use RetailCDXUploadReschedule class
        if (schedule.ScheduleType == RetailCDXDownloadUpload::Upload && parameterSet > 0)
        {
            throw Global::error(strFmt("@REX4160598", schedule.Name));
        }

        RetailCDXDataGroup dataGroup;

        // full sync / re-run: data group must be specified
        if (parameterSet > 0)
        {
            select firstonly RecId, Name, ChannelSchema from dataGroup
                where dataGroup.RecId == dataGroupRecID;

            if (!dataGroup)
            {
                // data group does not exist
                throw Global::error(strFmt("@REX4160599", dataGroupRecID));
            }
        }

        // rerun:
        //   job ID must be specified
        //   job must belong to schedule
        //   channel schema on job and data group must match
        //   rowversion must be specified
        if (parameterSet == ParamRerunConst)
        {
            RetailConnSchedulerJobTable job;

            select firstonly RecId, RetailConnChannelSchema from job
                where job.JobId == jobID;

            if (!job)
            {
                // job does not exist
                throw Global::error("@REX4160600", jobID);
            }

            RetailConnScheduleJobMapping scheduleJobMapping;

            select firstonly RecId from scheduleJobMapping
                where scheduleJobMapping.ScheduleRecId == scheduleRecID
                   && scheduleJobMapping.SchedulerJobId == jobID;

            if (!scheduleJobMapping)
            {
                // job is not included in schedule
                throw Global::error(strFmt("@REX4160601", jobID, schedule.Name));
            }

            if (job.RetailConnChannelSchema != dataGroup.ChannelSchema)
            {
                // channel schema on job does not match with data group
                throw Global::error(strFmt("@REX4160602", jobID, dataGroup.Name));
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>validateDataGroup</Name>
				<Source><![CDATA[
    private static void validateDataGroup(RefRecId _dataGroupRecID)
    {
        RetailConnDatabaseProfile dataStore;
        RetailCDXDataGroup dataGroup;
        RetailChannelTable channelTable;
        RetailCDXDataStoreChannel dataStoreChannel;

        while select RecId, Name from dataGroup
                where dataGroup.RecId == _dataGroupRecID
            join RecId, Name from dataStore
                where dataGroup.RecId == dataStore.DataGroup
            join RecId, Channel from dataStoreChannel
                where dataStore.RecId == dataStoreChannel.DatabaseProfile
        {
            if (dataStore && dataStoreChannel)
            {
                select firstonly RecId from channelTable where channelTable.RecId == dataStoreChannel.Channel;
                if (!channelTable)
                {
                    // channel does not exist in RetailChannelDatabase but has a record in RetailCDXDataStoreChannel.
                    throw Global::error(strFmt("@Retail:RetailCDXInvalidChannelError", dataStore.Name, dataGroup.Name));
                }
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>main</Name>
				<Source><![CDATA[
    static void main(Args args)
    {
        RetailCDXScheduleRunner    scheduleRunner;

        scheduleRunner = new RetailCDXScheduleRunner();

        if (scheduleRunner.prompt())
        {
            scheduleRunner.runOperation();
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>canRunInNewSession</Name>
				<Source><![CDATA[
    /// <summary>
    /// Describes whether the class is designed for execution in a new session.
    /// </summary>
    /// <returns>
    /// false.
    /// </returns>
    protected boolean canRunInNewSession()
    {
        return false;
    }

]]></Source>
			</Method>
			<Method>
				<Name>new</Name>
				<Source><![CDATA[
    /// <summary>
    /// Instantiates a <c>RetailCDXSchedulerRunner</c> class.
    /// </summary>
    public void new()
    {
        logger = new RetailCDXScheduleLogger(this);
        this.correlationId = newGuid();
        super();
    }

]]></Source>
			</Method>
			<Method>
				<Name>getScheduleName</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the schedule name.
    /// </summary>
    /// <returns>The schedule name.</returns>
    internal str getScheduleName()
    {
        return RetailConnSchedule::findByRecId(this.paramScheduleRecID()).Name;
    }

]]></Source>
			</Method>
			<Method>
				<Name>getRecurrenceData</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the batch recurrence data.
    /// </summary>
    /// <returns>A string representing the batch recurrence data.</returns>
    internal str getRecurrenceData()
    {
        str recurrenceStr;
        if (this.batchHeader)
        {
            SysRecurrenceData recurrenceData = this.batchHeader.parmRecurrenceData();
            recurrenceStr = new SysRecurrence(recurrenceData).toString();
        }

        return recurrenceStr;
    }

]]></Source>
			</Method>
			<Method>
				<Name>queueInBatch</Name>
				<Source><![CDATA[
    /// <summary>
    /// Queues the distribution schedule in batch to run it on the specified recurrence.
    /// </summary>
    /// <param name = "_schedulerRunner">The schedule runner object.</param>
    /// <param name = "recurrence">The batch recurrence.</param>
    /// <returns>The batch job's record Id.</returns>
    /// <remarks>Note that the default recurrence creates a batch which runs every 10mins. For creating a batch with no recurrence the recurrence argument should be set to conNull().</remarks>
    public static RefRecId queueInBatch(RetailCDXScheduleRunner _schedulerRunner, SysRecurrenceData recurrence = SysRecurrence::defaultRecurrence())
    {
        RetailCDXScheduleLogger logger = _schedulerRunner.logger;

        BatchHeader batchHeader = BatchHeader::construct();
        batchHeader.addTask(_schedulerRunner);

        // only set the recurrence data if recurrence data is explicitly provided and is not null.
        if (recurrence)
        {
            batchHeader.parmRecurrenceData(recurrence); //setting conNull() is also treated as using SysRecurrence::getDefaultRecurrence so skip when recurrence argument is conNull() so that the batch is created without recurrence.
        }

        _schedulerRunner.batchHeader = batchHeader;
        
        _schedulerRunner.saveBatchHeaderWithRetry();

        logger.logCDXScheduleRunnerBatchCreated();

        return batchHeader.parmBatchHeaderId();
    }

]]></Source>
			</Method>
			<Method>
				<Name>mustGoBatch</Name>
				<Source><![CDATA[
    /// <summary>
    /// The flag which will force the class run in batch mode.
    /// </summary>
    /// <returns>True if the scheduler class is forced to run in batch mode; false otherwise.</returns>
    /// <remarks>Overriden method from RunBaseBatch.</remarks>
    public boolean mustGoBatch()
    {
        return !RetailCdxFeatureControl::isForceScheduleInBatchDisabled();
    }

]]></Source>
			</Method>
			<Method>
				<Name>prompt</Name>
				<Source><![CDATA[
    public boolean prompt()
    {
        boolean ret;

        ret = super();

        if (this.batchInfo().parmBatchId() && this.batchInfo().fieldBatchExecuteValue())
        {
            this.batchHeader = this.batchInfo().parmBatchHeader();
            logger.logCDXScheduleRunnerBatchCreated();
        }

        return ret;
    }

]]></Source>
			</Method>
			<Method>
				<Name>saveBatchHeaderWithRetry</Name>
				<Source><![CDATA[
    /// <summary>
    /// Saves the batch header and retries the operation if there is an update conflict or a deadlock.
    /// </summary>
    internal void saveBatchHeaderWithRetry()
    {
        #OCCRetryCount
        try
        {
            RetailCDXScheduleRunner::saveBatchHeader(this.batchHeader);
        }
        catch (Exception::UpdateConflict)
        {
            if (xSession::currentRetryCount() < #RetryNum)
            {
                logger.logCDXScheduleUpdateSchedulerBatchHeaderUpdateConflictRetry(xSession::currentRetryCount() + 1); // log a warning event when there is a update conflict
                retry; // retry if there is an update conflic while saving the batch header.
            }
            else
            {
                throw Exception::UpdateConflictNotRecovered;
            }
        }
        catch (Exception::Deadlock)
        {
            if (xSession::currentRetryCount() < #RetryNum)
            {
                logger.logCDXScheduleUpdateSchedulerBatchHeaderDeadlockRetry(xSession::currentRetryCount() + 1);  // log a warning event when there is a deadlock
                retry;  // retry if there is a deadlock while saving the batch header.
            }
            else
            {
                throw Exception::Deadlock;
            }
        }
    }

]]></Source>
			</Method>
			<Method>
				<Name>getNumberOfUploadBatchTasksRequired</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the number of upload batch tasks required to process the specified number of upload sessions.
    /// </summary>
    /// <param name = "sessionCount">The number of upload session ready to be processed.</param>
    /// <returns>The number of batch tasks .</returns>
    internal int getNumberOfUploadBatchTasksRequired(int sessionCount)
    {
        if (sessionCount == 0)
        {
            return 0;
        }

        int totalNumberOfBatchThreads = this.getTotalNumberOfBatchThreads();

        int maxNumberOfUploadProcessingBatchTasksAllowed = RetailCDXFeatureControl::getMaxNumberOfUploadProcessingBatchTasksAllowed();
        
        // need to make sure we do not use more than one fourth of the total available batch thread.
        if (maxNumberOfUploadProcessingBatchTasksAllowed > totalNumberOfBatchThreads/4)
        {
            maxNumberOfUploadProcessingBatchTasksAllowed = totalNumberOfBatchThreads/4;
        }

        // if the number of upload sessions is small we use one task.
        if (sessionCount < maxNumberOfUploadProcessingBatchTasksAllowed * 2 || maxNumberOfUploadProcessingBatchTasksAllowed == 0)
        {
            maxNumberOfUploadProcessingBatchTasksAllowed = 1;
        }

        return maxNumberOfUploadProcessingBatchTasksAllowed;
    }

]]></Source>
			</Method>
			<Method>
				<Name>getTotalNumberOfBatchThreads</Name>
				<Source><![CDATA[
    /// <summary>
    /// Gets the total number of batch threads available across all AOS instances.
    /// </summary>
    /// <returns>The total number of batch threads.</returns>
    internal int getTotalNumberOfBatchThreads()
    {
        SysServerConfig     sysServerConfig;
        BatchServerConfig   batchServerConfig;

        select sum(MaxBatchSessions) from batchServerConfig
            exists join sysServerConfig
                where batchServerConfig.ServerId == sysServerConfig.ServerId;

        return batchServerConfig.MaxBatchSessions;
    }

]]></Source>
			</Method>
			<Method>
				<Name>saveBatchHeader</Name>
				<Source><![CDATA[
    private static void saveBatchHeader(BatchHeader _batchHeader)
    {
        ttsbegin;
        _batchHeader.save();
        ttscommit;
    }

]]></Source>
			</Method>
			<Method>
				<Name>isRetryable</Name>
				<Source><![CDATA[
    /// <summary>
    /// Specifies if the batch task is retryable for transient exceptions or not.
    /// </summary>
    /// <returns>
    /// If true is returned, the batch task is retryable, otherwise it is not.
    /// </returns>
    [Hookable(false)]
    final boolean isRetryable()
    {
        return true;
    }

]]></Source>
			</Method>
			<Method>
				<Name>initRecurrenceData</Name>
				<Source><![CDATA[
    /// <summary>
    /// Initiates recurrence data for current batch header.
    /// </summary>
    /// <param name="_sysRecurrenceData">
    /// The variable of object <c>SysRecurrenceData</c>; optional.
    /// </param>
    internal void initRecurrenceData(SysRecurrenceData _sysRecurrenceData = SysRecurrence::defaultRecurrence())
    {
        this.batchInfo().parmBatchHeader().parmRecurrenceData(_sysRecurrenceData);
    }

]]></Source>
			</Method>
		</Methods>
	</SourceCode>
</AxClass>